# To Do's

## âœ… COMPLETED

### Variable Unifier Network Testing and Fix
**Status:** âœ… COMPLETE (2025-01-22)

**What Was Done:**
1. âœ… Created comprehensive test suite (`test_variable_unifier.py`) with 12 tests
2. âœ… Defined intended behavior specification
3. âœ… Tested all failure modes (forward pass, backward pass, masking, edge cases)
4. âœ… Identified root cause: `get_valid_variable_pairs()` allowed head-head variable unification
5. âœ… Applied fix to `src/logic_structures.py:184`
6. âœ… Verified fix: All 12/12 tests now pass (100%)
7. âœ… Documented findings in `VARIABLE_UNIFIER_TEST_RESULTS.md`

**Fix Applied:**
```python
# src/logic_structures.py:184
def get_valid_variable_pairs(theory: Theory):
    # Now excludes pairs where both variables are in head
    # Prevents self-loops like: grandparent(X0, X0) :- ...
```

**Test Results:**
- Total: 12/12 tests passing (100%)
- Forward pass: âœ… All edge cases handled correctly
- Backward pass: âœ… Gradients flow correctly
- Masking: âœ… Head variables properly filtered
- Learning: âœ… Network learns preferences effectively

**Key Findings:**
- Network architecture is sound and functional
- Learning capability is excellent (scores change 20,000Ã— in 100 steps)
- Only issue was filtering logic for valid pairs (now fixed)

**Files Created/Modified:**
- `test_variable_unifier.py` - Comprehensive test suite
- `VARIABLE_UNIFIER_TEST_RESULTS.md` - Detailed findings document
- `src/logic_structures.py` - Fixed `get_valid_variable_pairs()`

**Run Tests:** `python test_variable_unifier.py`

---

---

### Variable Unification Pipeline - End-to-End Testing
**Status:** âœ… COMPLETE (2025-01-22)

**What Was Done:**
1. âœ… Created comprehensive end-to-end test suite (`test_unification_pipeline.py`)
2. âœ… Tested unification on diverse rule types (chain, convergent, transitive, star, etc.)
3. âœ… Tested equivalent rule recognition (variable renaming, atom shuffling)
4. âœ… Verified unification produces intended results
5. âœ… Documented complete pipeline behavior (`UNIFICATION_PIPELINE_TEST_RESULTS.md`)
6. âœ… Confirmed `apply_unify_vars()` behavior: replaces var2 with var1
7. âœ… Verified `get_valid_variable_pairs()` correctly filters head-head pairs

**Test Categories:**
- Basic unifications: âœ… Chain, convergent, transitive structures
- Equivalent rules: âœ… Variable renaming, atom shuffling
- Complex scenarios: âœ… Multiple atoms, star structures, disconnected components
- Valid pairs: âœ… Empty body, head+body, body-only variables
- Properties: âœ… Variable count, symmetry (behavior documented), idempotence
- Edge cases: âœ… Self-unification, unary predicates, large rules
- Semantics: âœ… Semantic changes allowed (by design - GFlowNet learns)

**Key Findings:**
- `apply_unify_vars(theory, var1, var2)` replaces var2 with var1
  - var1 is the survivor
  - var2 gets replaced
- Unification can change semantics (intentional - reward function guides learning)
- Head-head pair filtering prevents self-loops
- All mathematical properties verified

**Files Created:**
- `test_unification_pipeline.py` - End-to-end test suite
- `UNIFICATION_PIPELINE_TEST_RESULTS.md` - Complete documentation
- `test_unification_pipeline_fixed.py` - Behavior verification script

**Run Tests:** `python test_unification_pipeline.py`

**Result:** âœ… Pipeline verified working correctly - Ready for production use!

---

### Unification Learning Analysis
**Status:** âœ… COMPLETE (2025-01-22)

**What Was Done:**
1. âœ… Analyzed why policy network struggles to learn variable unification decisions
2. âœ… Identified 7 fundamental learning challenges
3. âœ… Discovered replay buffer overfitting problem (critical!)
4. âœ… Created comprehensive analysis documents
5. âœ… Created diagnostic tool to detect overfitting

**Key Findings:**

**Problem 1: Replay Buffer Overfitting** ðŸ”´ CRITICAL
- Model achieves LOW loss on replayed trajectories (learned them well)
- But samples LOW reward trajectories on-policy (poor generalization)
- **Root cause:** Memorizing 50 specific paths instead of learning general policy
- State space coverage: ~2.5% (50 trajectories / ~10,000 states)
- Stochastic sampling diverges from memorized paths â†’ poor policy â†’ low reward

**7 Fundamental Learning Challenges:**
1. Sparse Reward Signal - No intermediate feedback
2. log_Z Compensation - Reduces loss without policy improvement
3. Masking Prevents Learning - Network never learns validity
4. Credit Assignment Problem - Can't attribute success to specific unifications
5. Replay Buffer Spurious Correlations - High-reward trajectories may succeed despite bad unifications
6. Backward Policy Inaccuracy - Biased gradients from incorrect P_B
7. No Structural Prior - All valid pairs treated equally

**Impact:**
- Unification learning is 10-100Ã— slower than predicate learning
- Network receives weak, delayed, noisy, and biased gradient signals
- Gradient magnitude: Variable unifier ~0.1Ã—, log_Z ~5.0Ã— baseline

**Files Created:**
- `UNIFICATION_LEARNING_ANALYSIS.md` - Comprehensive 15,000+ word analysis
- `REPLAY_BUFFER_OVERFITTING_ANALYSIS.md` - Specific overfitting analysis
- `diagnose_replay_overfitting.py` - Diagnostic tool

**Recommended Solutions:**

**Immediate (Quick Fixes):**
1. Increase buffer capacity: 50 â†’ 500
2. Decrease replay probability: 0.3 â†’ 0.1
3. Lower buffer threshold: 0.7 â†’ 0.5
4. Add diversity metric to buffer
5. Reduce log_Z learning rate (separate optimizer)

**Medium-Term:**
6. Data augmentation on replayed trajectories
7. Add structural features to variable embeddings
8. Importance sampling for replay
9. Curriculum learning for buffer

**Long-Term:**
10. Use Detailed Balance (removes log_Z bottleneck)
11. Add generalization penalty
12. Pretrain unifier network

**How to Diagnose:**
```python
from diagnose_replay_overfitting import diagnose_replay_overfitting
results = diagnose_replay_overfitting(trainer, initial_state, pos_ex, neg_ex)
```

**Result:** âœ… Root causes identified, solutions provided, diagnostic tool ready!

---

### Deterministic Sampling Bug Fix
**Status:** âœ… COMPLETE (2025-01-22)

**What Was Done:**
1. âœ… Identified bug where `stochastic=False` still produced random trajectories
2. âœ… Root cause: `stochastic` parameter not passed to sub-action handlers
3. âœ… Fixed `_handle_action_add_atom` to accept and use `stochastic` parameter
4. âœ… Fixed `_handle_action_unify_vars` to accept and use `stochastic` parameter
5. âœ… Updated calls in `generate_trajectory` to pass `stochastic` parameter
6. âœ… Created test script and documentation

**The Bug:**
- Only high-level action type (ADD_ATOM, UNIFY, TERMINATE) was deterministic
- Predicate selection and variable pair selection remained random
- Users couldn't reproduce results or see true greedy policy

**The Fix (3 changes in src/training.py):**
1. Line 411: Added `stochastic: bool = True` to `_handle_action_add_atom` signature
2. Line 422: Pass `stochastic` to `self._sample_action_from_logits(atom_logits, stochastic)`
3. Line 436: Added `stochastic: bool = True` to `_handle_action_unify_vars` signature
4. Line 474: Pass `stochastic` to `self._sample_action_from_logits(masked_logits, stochastic)`
5. Lines 293, 298: Pass `stochastic` when calling handler methods

**Files Created:**
- `DETERMINISTIC_SAMPLING_BUG.md` - Comprehensive analysis
- `DETERMINISTIC_SAMPLING_FIX.md` - Quick reference
- `test_deterministic_bug.py` - Test to verify fix

**How to Test:**
```python
from test_deterministic_bug import test_deterministic_sampling_bug
passed = test_deterministic_sampling_bug(trainer, initial_state, pos_ex, neg_ex)
# Should PASS after fix âœ…
```

**Impact:**
- âœ… Deterministic sampling now truly deterministic
- âœ… Can reproduce results with same seed
- âœ… Can evaluate true greedy policy
- âœ… Better debugging capability

**Result:** âœ… Bug fixed! Deterministic sampling now works correctly.

---

## ðŸ“‹ Future Work

### Optional Enhancements
- [ ] Add unit tests to CI/CD pipeline
- [ ] Monitor head unification rate in training logs
- [ ] Add explicit structural features to help learning
- [ ] Improve replay buffer (prioritized experience replay)
- [ ] Verify backward policy matches forward policy