{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4bf38b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7de0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/Users/jq23948/Documents/GFLOWNET-ILP')\n",
    "\n",
    "import numpy as np\n",
    "from src.logic_structures import get_initial_state, theory_to_string\n",
    "from src.logic_engine import LogicEngine, Example\n",
    "from src.reward import RewardCalculator\n",
    "from src.graph_encoder_enhanced import EnhancedGraphConstructor, EnhancedStateEncoder\n",
    "from src.gflownet_models import HierarchicalGFlowNet\n",
    "from src.training import GFlowNetTrainer\n",
    "from src.exploration import get_combined_strategy\n",
    "from src.visualization import TrainingVisualizer\n",
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76b7225e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem setup\n",
    "background_facts = [\n",
    "    Example('parent', ('alice', 'bob')),\n",
    "    Example('parent', ('bob', 'charlie')),\n",
    "    Example('parent', ('eve', 'frank')),\n",
    "    Example('parent', ('frank', 'grace')),\n",
    "    Example('parent', ('diana', 'henry')),\n",
    "    Example('parent', ('henry', 'irene')),\n",
    "    Example('parent', ('grace', 'jack'))\n",
    "]\n",
    "\n",
    "\n",
    "positive_examples = [\n",
    "    Example('grandparent', ('alice', 'charlie')),\n",
    "    Example('grandparent', ('eve', 'grace')),\n",
    "    Example('grandparent', ('diana', 'irene')),\n",
    "    Example('grandparent', ('frank', 'jack'))\n",
    "]\n",
    "\n",
    "negative_examples = [\n",
    "    Example('grandparent', ('alice', 'alice')),\n",
    "    Example('grandparent', ('bob', 'bob')),\n",
    "    Example('grandparent', ('alice', 'eve')),\n",
    "    Example('grandparent', ('bob', 'frank')),\n",
    "    Example('grandparent', ('eve', 'frank')),\n",
    "]\n",
    "\n",
    "predicate_vocab = ['parent']\n",
    "predicate_arities = {'parent': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e58c4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save configuration\n",
    "config = {\n",
    "    'problem': 'grandparent',\n",
    "    'predicate_vocab': predicate_vocab,\n",
    "    'predicate_arities': predicate_arities,\n",
    "\n",
    "    'logic_engine_max_depth': 10,\n",
    "    'num_episodes': 10000,\n",
    "    'embedding_dim': 32,\n",
    "    'hidden_dim': 64,\n",
    "    'num_layers_encoder': 2,\n",
    "    'learning_rate': 1e-4,\n",
    "    'max_body_length': 4,\n",
    "\n",
    "    'use_sophisticated_backward': True,\n",
    "\n",
    "    'use_f1': True,\n",
    "    'weight_precision': 0.5,\n",
    "    'weight_recall': 0.5,\n",
    "    'weight_simplicity': 0.05,\n",
    "    'disconnected_var_penalty': 0.2,\n",
    "    'self_loop_penalty': 0.3,\n",
    "    'free_var_penalty': 1.0,\n",
    "\n",
    "    'use_detailed_balance': True,\n",
    "\n",
    "    'use_replay_buffer': True,\n",
    "    'replay_probability': 0.5,\n",
    "    'replay_buffer_capacity': 50,\n",
    "    'buffer_reward_threshold': 0.5,\n",
    "\n",
    "    'reward_weighted_loss': False,\n",
    "    'reward_scale_alpha': 10.0,\n",
    "\n",
    "    'num_background_facts': len(background_facts),\n",
    "    'num_positive_examples': len(positive_examples),\n",
    "    'num_negative_examples': len(negative_examples),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bf899c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "METHOD DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "Goal: Learn grandparent(X, Y) rule from examples\n",
      "\n",
      "Background Knowledge (7 facts):\n",
      "  parent(alice, bob)\n",
      "  parent(bob, charlie)\n",
      "  parent(eve, frank)\n",
      "  parent(frank, grace)\n",
      "  parent(diana, henry)\n",
      "  parent(henry, irene)\n",
      "  parent(grace, jack)\n",
      "\n",
      "Positive Examples (4):\n",
      "  grandparent(alice, charlie)\n",
      "  grandparent(eve, grace)\n",
      "  grandparent(diana, irene)\n",
      "  grandparent(frank, jack)\n",
      "\n",
      "Negative Examples (5):\n",
      "  grandparent(alice, alice)\n",
      "  grandparent(bob, bob)\n",
      "  grandparent(alice, eve)\n",
      "  grandparent(bob, frank)\n",
      "  grandparent(eve, frank)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"METHOD DEMONSTRATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGoal: Learn grandparent(X, Y) rule from examples\")\n",
    "print(f\"\\nBackground Knowledge ({len(background_facts)} facts):\")\n",
    "for fact in background_facts:\n",
    "    print(f\"  {fact.predicate_name}({', '.join(fact.args)})\")\n",
    "\n",
    "print(f\"\\nPositive Examples ({len(positive_examples)}):\")\n",
    "for ex in positive_examples:\n",
    "    print(f\"  {ex.predicate_name}({', '.join(ex.args)})\")\n",
    "\n",
    "print(f\"\\nNegative Examples ({len(negative_examples)}):\")\n",
    "for ex in negative_examples:\n",
    "    print(f\"  {ex.predicate_name}({', '.join(ex.args)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "413df16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to: results/run_20251021_134418\n",
      "âœ“ Saved configuration to results/run_20251021_134418/config.json\n"
     ]
    }
   ],
   "source": [
    "logic_engine = LogicEngine(max_depth=config['logic_engine_max_depth'], background_facts=background_facts)\n",
    "reward_calc = RewardCalculator(\n",
    "    logic_engine,\n",
    "    weight_precision=config['weight_precision'],      # Penalize false positives (covering negatives)\n",
    "    weight_recall=config[\"weight_recall\"],          # Penalize false negatives (missing positives)\n",
    "    weight_simplicity=config['weight_simplicity'],      # Small penalty for longer rules\n",
    "    disconnected_var_penalty=config['disconnected_var_penalty'],\n",
    "    self_loop_penalty= config['self_loop_penalty'],        # Moderate penalty for self-loops\n",
    "    free_var_penalty=config['free_var_penalty'],\n",
    "    use_f1=config['use_f1']                 # Use F1-score for balanced precision-recall\n",
    ")\n",
    "graph_constructor = EnhancedGraphConstructor(config['predicate_vocab'])\n",
    "state_encoder = EnhancedStateEncoder(\n",
    "    predicate_vocab_size=len(config['predicate_vocab']),\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    num_layers=config['num_layers_encoder']\n",
    ")\n",
    "gflownet = HierarchicalGFlowNet(\n",
    "    embedding_dim=config['embedding_dim'],\n",
    "    num_predicates=len(config['predicate_vocab']),\n",
    "    hidden_dim=config['hidden_dim'],\n",
    "    use_sophisticated_backward=config['use_sophisticated_backward'],\n",
    "    predicate_vocab=config['predicate_vocab']\n",
    ")\n",
    "\n",
    "\n",
    "# exploration = get_combined_strategy(\"aggressive\")\n",
    "\n",
    "\n",
    "trainer = GFlowNetTrainer(\n",
    "    state_encoder=state_encoder,\n",
    "    gflownet=gflownet,\n",
    "    graph_constructor=graph_constructor,\n",
    "    reward_calculator=reward_calc,\n",
    "    predicate_vocab=config['predicate_vocab'],\n",
    "    predicate_arities=config['predicate_arities'],\n",
    "    learning_rate=config['learning_rate'],\n",
    "    exploration_strategy=None,  # No exploration strategy for demo\n",
    "    use_detailed_balance=config['use_detailed_balance'],\n",
    "    use_replay_buffer=config['use_replay_buffer'],\n",
    "    replay_buffer_capacity=config['replay_buffer_capacity'],\n",
    "    reward_weighted_loss=config['reward_weighted_loss'],\n",
    "    replay_probability=config['replay_probability'],\n",
    "    max_body_length=config['max_body_length'],\n",
    "    buffer_reward_threshold=config['buffer_reward_threshold'],\n",
    "    reward_scale_alpha=config['reward_scale_alpha']\n",
    "    \n",
    ")\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = TrainingVisualizer(\n",
    "    experiment_name=config['problem'],\n",
    "    output_dir=\"results\"\n",
    ")\n",
    "\n",
    "\n",
    "visualizer.save_config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6whprvolit",
   "metadata": {},
   "source": [
    "# Contrastive Pre-Training\n",
    "\n",
    "**Problem:** The graph encoder initially produces very similar embeddings for all rules, even those with different semantics. This makes it hard for the GFlowNet to learn which states lead to good rewards.\n",
    "\n",
    "**Solution:** Pre-train the encoder using contrastive learning BEFORE GFlowNet training:\n",
    "- **Positive pairs**: Same rule with renamed variables â†’ should have SIMILAR embeddings\n",
    "- **Negative pairs**: Different variable connections â†’ should have DIFFERENT embeddings\n",
    "\n",
    "This teaches the encoder to distinguish structural differences in rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "pfe57cmf8ul",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CONTRASTIVE PRE-TRAINING\n",
      "================================================================================\n",
      "\n",
      "Step 1: Testing encoder BEFORE pre-training\n",
      "--------------------------------------------------------------------------------\n",
      "Rule 1 (chain):       grandparent(X0, X1) :- parent(X0, X2), parent(X2, X1)\n",
      "Rule 2 (convergent):  grandparent(X0, X1) :- parent(X0, X2), parent(X1, X2)\n",
      "\n",
      "Similarity: 0.999996\n",
      "Status: âŒ TOO SIMILAR (need pre-training)\n",
      "\n",
      "\n",
      "Step 2: Generating base rules for pre-training\n",
      "--------------------------------------------------------------------------------\n",
      "Generated 101 diverse base rules\n",
      "\n",
      "\n",
      "Step 3: Running contrastive pre-training\n",
      "--------------------------------------------------------------------------------\n",
      "Pre-training for 200 epochs (this may take a few minutes)...\n",
      "================================================================================\n",
      "CONTRASTIVE PRE-TRAINING\n",
      "================================================================================\n",
      "\n",
      "Training for 200 epochs with 101 base rules\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"tuple\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Run pre-training (200 epochs takes ~2-3 minutes)\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPre-training for 200 epochs (this may take a few minutes)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m losses = \u001b[43mpretrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_rules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Test AFTER pre-training\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStep 4: Testing encoder AFTER pre-training\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GFLOWNET-ILP/contrastive_pretraining.py:276\u001b[39m, in \u001b[36mContrastivePreTrainer.pretrain\u001b[39m\u001b[34m(self, base_rules, num_epochs, verbose)\u001b[39m\n\u001b[32m    273\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m epochs with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(base_rules)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m base rules\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_rules\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m     losses.append(loss)\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mand\u001b[39;00m epoch % \u001b[32m10\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GFLOWNET-ILP/contrastive_pretraining.py:246\u001b[39m, in \u001b[36mContrastivePreTrainer.train_epoch\u001b[39m\u001b[34m(self, base_rules, num_negatives)\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Train for one epoch.\"\"\"\u001b[39;00m\n\u001b[32m    244\u001b[39m \u001b[38;5;28mself\u001b[39m.state_encoder.train()\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m anchors, positives, negatives = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_training_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_rules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_negatives\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_negatives\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.criterion(anchors, positives, negatives)\n\u001b[32m    252\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GFLOWNET-ILP/contrastive_pretraining.py:221\u001b[39m, in \u001b[36mContrastivePreTrainer.generate_training_batch\u001b[39m\u001b[34m(self, base_rules, num_negatives)\u001b[39m\n\u001b[32m    217\u001b[39m     neg_theory = \u001b[38;5;28mself\u001b[39m.augmenter.variable_connection_change(\n\u001b[32m    218\u001b[39m         theory, \u001b[38;5;28mself\u001b[39m.predicate_vocab, \u001b[38;5;28mself\u001b[39m.predicate_arities\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     neg_theory = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maugmenter\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_disconnected_atom\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredicate_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredicate_arities\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m neg_emb = \u001b[38;5;28mself\u001b[39m.get_embedding(neg_theory)\n\u001b[32m    226\u001b[39m neg_embs.append(neg_emb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GFLOWNET-ILP/contrastive_pretraining.py:166\u001b[39m, in \u001b[36mRuleAugmenter.add_disconnected_atom\u001b[39m\u001b[34m(theory, predicate_vocab, predicate_arities)\u001b[39m\n\u001b[32m    163\u001b[39m new_atom = Atom(predicate_name=pred_name, args=new_args)\n\u001b[32m    165\u001b[39m rule = theory[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m new_body = \u001b[43mrule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_atom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [Rule(head=rule.head, body=new_body)]\n",
      "\u001b[31mTypeError\u001b[39m: can only concatenate list (not \"tuple\") to list"
     ]
    }
   ],
   "source": [
    "from contrastive_pretraining import ContrastivePreTrainer, generate_base_rules\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from src.logic_structures import Rule, Atom, Variable\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CONTRASTIVE PRE-TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Helper function to create test rules\n",
    "def create_test_rule(head_pred, head_args, body_atoms_list):\n",
    "    head_vars = [Variable(id=vid) for vid in head_args]\n",
    "    head = Atom(predicate_name=head_pred, args=tuple(head_vars))\n",
    "    body_atoms = []\n",
    "    for pred_name, var_ids in body_atoms_list:\n",
    "        vars = [Variable(id=vid) for vid in var_ids]\n",
    "        body_atoms.append(Atom(predicate_name=pred_name, args=tuple(vars)))\n",
    "    rule = Rule(head=head, body=tuple(body_atoms))\n",
    "    return [rule]\n",
    "\n",
    "def get_test_embedding(theory):\n",
    "    graph_data = graph_constructor.theory_to_graph(theory)\n",
    "    state_embedding, _ = state_encoder(graph_data)\n",
    "    return state_embedding.squeeze(0).detach().numpy()\n",
    "\n",
    "# Test BEFORE pre-training\n",
    "print(\"\\nStep 1: Testing encoder BEFORE pre-training\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "rule_chain = create_test_rule('grandparent', [0, 1], [('parent', (0, 2)), ('parent', (2, 1))])\n",
    "rule_convergent = create_test_rule('grandparent', [0, 1], [('parent', (0, 2)), ('parent', (1, 2))])\n",
    "\n",
    "emb_chain_before = get_test_embedding(rule_chain)\n",
    "emb_conv_before = get_test_embedding(rule_convergent)\n",
    "sim_before = cosine_similarity([emb_chain_before], [emb_conv_before])[0, 0]\n",
    "\n",
    "print(f\"Rule 1 (chain):       grandparent(X0, X1) :- parent(X0, X2), parent(X2, X1)\")\n",
    "print(f\"Rule 2 (convergent):  grandparent(X0, X1) :- parent(X0, X2), parent(X1, X2)\")\n",
    "print(f\"\\nSimilarity: {sim_before:.6f}\")\n",
    "print(f\"Status: {'âŒ TOO SIMILAR (need pre-training)' if sim_before > 0.95 else 'âœ… Already good'}\")\n",
    "\n",
    "# Generate base rules for pre-training\n",
    "print(\"\\n\\nStep 2: Generating base rules for pre-training\")\n",
    "print(\"-\" * 80)\n",
    "base_rules = generate_base_rules(predicate_vocab, predicate_arities, num_rules=100)\n",
    "print(f\"Generated {len(base_rules)} diverse base rules\")\n",
    "\n",
    "# Pre-train the encoder\n",
    "print(\"\\n\\nStep 3: Running contrastive pre-training\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "pretrainer = ContrastivePreTrainer(\n",
    "    state_encoder=state_encoder,\n",
    "    graph_constructor=graph_constructor,\n",
    "    predicate_vocab=predicate_vocab,\n",
    "    predicate_arities=predicate_arities\n",
    ")\n",
    "\n",
    "# Run pre-training (200 epochs takes ~2-3 minutes)\n",
    "print(\"Pre-training for 200 epochs (this may take a few minutes)...\")\n",
    "losses = pretrainer.pretrain(base_rules, num_epochs=200, verbose=True)\n",
    "\n",
    "# Test AFTER pre-training\n",
    "print(\"\\n\\nStep 4: Testing encoder AFTER pre-training\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "emb_chain_after = get_test_embedding(rule_chain)\n",
    "emb_conv_after = get_test_embedding(rule_convergent)\n",
    "sim_after = cosine_similarity([emb_chain_after], [emb_conv_after])[0, 0]\n",
    "\n",
    "print(f\"Rule 1 (chain):       grandparent(X0, X1) :- parent(X0, X2), parent(X2, X1)\")\n",
    "print(f\"Rule 2 (convergent):  grandparent(X0, X1) :- parent(X0, X2), parent(X1, X2)\")\n",
    "print(f\"\\nSimilarity: {sim_after:.6f}\")\n",
    "print(f\"Status: {'âœ… IMPROVED! Can now distinguish semantics' if sim_after < 0.90 else 'âš ï¸ Still too similar'}\")\n",
    "\n",
    "# Visualize improvement\n",
    "print(\"\\n\\nStep 5: Visualizing improvement\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "improvement = sim_before - sim_after\n",
    "print(f\"\\nImprovement: {improvement:.6f} reduction in similarity\")\n",
    "print(f\"  Before: {sim_before:.6f}\")\n",
    "print(f\"  After:  {sim_after:.6f}\")\n",
    "\n",
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curve\n",
    "axes[0].plot(losses, linewidth=2, color='blue')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Contrastive Loss', fontsize=12)\n",
    "axes[0].set_title('Pre-training Loss Curve', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Before/After comparison\n",
    "categories = ['Before\\nPre-training', 'After\\nPre-training']\n",
    "similarities = [sim_before, sim_after]\n",
    "colors = ['red' if s > 0.90 else 'green' for s in similarities]\n",
    "\n",
    "bars = axes[1].bar(categories, similarities, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "axes[1].axhline(y=0.90, color='orange', linestyle='--', linewidth=2, label='Target (<0.90)')\n",
    "axes[1].set_ylabel('Cosine Similarity', fontsize=12)\n",
    "axes[1].set_title('Embedding Similarity:\\nChain vs Convergent Pattern', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylim([0, 1.05])\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, sim in zip(bars, similarities):\n",
    "    height = bar.get_height()\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{sim:.4f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{visualizer.run_dir}/contrastive_pretraining_results.png', dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nâœ“ Visualization saved to: {visualizer.run_dir}/contrastive_pretraining_results.png\")\n",
    "plt.show()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PRE-TRAINING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if sim_after < 0.90:\n",
    "    print(\"\\nðŸŽ‰ SUCCESS! Pre-training was effective.\")\n",
    "    print(f\"   The encoder can now distinguish semantic differences.\")\n",
    "    print(f\"   Similarity reduced from {sim_before:.4f} to {sim_after:.4f}\")\n",
    "    print(\"\\nâœ“ The pre-trained encoder will now be used in GFlowNet training.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Pre-training helped but similarity is still high.\")\n",
    "    print(f\"   Similarity: {sim_before:.4f} â†’ {sim_after:.4f}\")\n",
    "    print(\"\\n   Consider:\")\n",
    "    print(\"   - More pre-training epochs (500-1000)\")\n",
    "    print(\"   - More diverse base rules\")\n",
    "    print(\"   - Using improved architecture (see improved_graph_encoder.py)\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9352cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING (10000 episodes)\n",
      "================================================================================\n",
      "0 {'loss': 18.95529556274414, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode    0: Mean Reward (last 100 episodes) = 0.0000 ---\n",
      "Episode    0: reward=0.0000, length=10\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X0, X0).\n",
      "1 {'loss': 18.83078384399414, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "2 {'loss': 20.999984741210938, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "3 {'loss': 41.6654167175293, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "4 {'loss': 20.983837127685547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "5 {'loss': 19.685344696044922, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "6 {'loss': 35.33517074584961, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "7 {'loss': 21.055641174316406, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "8 {'loss': 18.893789291381836, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "9 {'loss': 18.999862670898438, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "10 {'loss': 25.129751205444336, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "11 {'loss': 20.891000747680664, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "12 {'loss': 23.458864212036133, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "13 {'loss': 29.407773971557617, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "14 {'loss': 29.3742618560791, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "15 {'loss': 17.789100646972656, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "16 {'loss': 41.637939453125, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "17 {'loss': 20.88719940185547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "18 {'loss': 29.24540138244629, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "19 {'loss': 34.66918182373047, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "20 {'loss': 18.803030014038086, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "21 {'loss': 18.79507827758789, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "22 {'loss': 23.488981246948242, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "23 {'loss': 23.318021774291992, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "24 {'loss': 51.77711868286133, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "25 {'loss': 23.314464569091797, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "26 {'loss': 51.872859954833984, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "27 {'loss': 20.90805435180664, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "28 {'loss': 20.8264102935791, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "29 {'loss': 34.55308151245117, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "30 {'loss': 20.866893768310547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "31 {'loss': 51.80156326293945, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "32 {'loss': 18.958919525146484, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "33 {'loss': 18.919382095336914, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "34 {'loss': 23.378189086914062, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "35 {'loss': 20.65100860595703, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "36 {'loss': 51.733154296875, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "37 {'loss': 18.640422821044922, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "38 {'loss': 41.36500930786133, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "39 {'loss': 18.882375717163086, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "40 {'loss': 19.032920837402344, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "41 {'loss': 18.929584503173828, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "42 {'loss': 18.696842193603516, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "43 {'loss': 18.56065559387207, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "44 {'loss': 51.49394226074219, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "45 {'loss': 17.415742874145508, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "46 {'loss': 41.275020599365234, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "47 {'loss': 51.58521270751953, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "48 {'loss': 51.57073974609375, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "49 {'loss': 20.698583602905273, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "50 {'loss': 19.369626998901367, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "51 {'loss': 18.511329650878906, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "52 {'loss': 20.745471954345703, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "53 {'loss': 20.61469078063965, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "54 {'loss': 18.843685150146484, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "55 {'loss': 51.475975036621094, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "56 {'loss': 26.401386260986328, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "57 {'loss': 20.552276611328125, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "58 {'loss': 51.43645477294922, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "59 {'loss': 20.702144622802734, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "60 {'loss': 23.17331314086914, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "61 {'loss': 20.619037628173828, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "62 {'loss': 18.757991790771484, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "63 {'loss': 20.657445907592773, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "64 {'loss': 51.35905838012695, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "65 {'loss': 24.71998405456543, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "66 {'loss': 41.067787170410156, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "67 {'loss': 23.118717193603516, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "68 {'loss': 18.82200813293457, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "69 {'loss': 20.675071716308594, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "70 {'loss': 18.731082916259766, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "71 {'loss': 40.89699935913086, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "72 {'loss': 18.874019622802734, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "73 {'loss': 34.425594329833984, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "74 {'loss': 51.2310791015625, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "75 {'loss': 40.854331970214844, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "76 {'loss': 40.99396514892578, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "77 {'loss': 21.49877166748047, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "78 {'loss': 51.17555618286133, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "79 {'loss': 18.419593811035156, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "80 {'loss': 25.58596420288086, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "81 {'loss': 25.50977325439453, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "82 {'loss': 18.423187255859375, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "83 {'loss': 20.52724838256836, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "84 {'loss': 40.906288146972656, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "85 {'loss': 20.564090728759766, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "86 {'loss': 20.486539840698242, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "87 {'loss': 20.47435188293457, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "88 {'loss': 18.575510025024414, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "89 {'loss': 20.53421401977539, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "90 {'loss': 20.525192260742188, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "91 {'loss': 50.85906219482422, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "92 {'loss': 24.530765533447266, 'reward': 0.3023809523809524, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "93 {'loss': 50.83220291137695, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "94 {'loss': 20.413402557373047, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "95 {'loss': 40.63364028930664, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "96 {'loss': 18.668001174926758, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "97 {'loss': 20.372310638427734, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "98 {'loss': 40.598358154296875, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "99 {'loss': 20.35860252380371, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "100 {'loss': 20.241636276245117, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode  100: Mean Reward (last 100 episodes) = 0.0030 ---\n",
      "Episode  100: reward=0.0000, length=9\n",
      "  Latest sampled rule: grandparent(X2, X2) :- parent(X2, X2), parent(X2, X5), parent(X6, X8), parent(X8, X2).\n",
      "101 {'loss': 40.72351837158203, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "102 {'loss': 22.834016799926758, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "103 {'loss': 22.870344161987305, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "104 {'loss': 40.66532516479492, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "105 {'loss': 22.806621551513672, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "106 {'loss': 24.316486358642578, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "107 {'loss': 50.78425216674805, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "108 {'loss': 22.778942108154297, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "109 {'loss': 18.98314666748047, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "110 {'loss': 20.230533599853516, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "111 {'loss': 50.56711959838867, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "112 {'loss': 17.03160858154297, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "113 {'loss': 20.340925216674805, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "114 {'loss': 40.565895080566406, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "115 {'loss': 40.38714599609375, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "116 {'loss': 20.337209701538086, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "117 {'loss': 50.63022994995117, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "118 {'loss': 20.28449821472168, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "119 {'loss': 20.316152572631836, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "120 {'loss': 42.40652847290039, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "121 {'loss': 20.271806716918945, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "122 {'loss': 50.5465087890625, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "123 {'loss': 20.22330093383789, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "124 {'loss': 17.95113182067871, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "125 {'loss': 20.062711715698242, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "126 {'loss': 20.32358741760254, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "127 {'loss': 25.225460052490234, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "128 {'loss': 20.18218421936035, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "129 {'loss': 20.179637908935547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "130 {'loss': 28.157699584960938, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "131 {'loss': 21.105436325073242, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "132 {'loss': 16.788787841796875, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "133 {'loss': 40.29972839355469, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "134 {'loss': 20.01900291442871, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "135 {'loss': 17.910541534423828, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "136 {'loss': 17.273143768310547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "137 {'loss': 50.13211441040039, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "138 {'loss': 40.198490142822266, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "139 {'loss': 22.428688049316406, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "140 {'loss': 25.025484085083008, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "141 {'loss': 20.189895629882812, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "142 {'loss': 41.80397415161133, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "143 {'loss': 50.18976974487305, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "144 {'loss': 49.99584197998047, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "145 {'loss': 39.98618698120117, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "146 {'loss': 50.120975494384766, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "147 {'loss': 50.09477233886719, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "148 {'loss': 50.06849670410156, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "149 {'loss': 33.44477081298828, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "150 {'loss': 20.113500595092773, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "151 {'loss': 49.986515045166016, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "152 {'loss': 49.95967483520508, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "153 {'loss': 39.90635299682617, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "154 {'loss': 20.055715560913086, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "155 {'loss': 20.807994842529297, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "156 {'loss': 19.97127914428711, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "157 {'loss': 49.81822204589844, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "158 {'loss': 39.845603942871094, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "159 {'loss': 49.75980758666992, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "160 {'loss': 19.869571685791016, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "161 {'loss': 33.15522766113281, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "162 {'loss': 39.53997039794922, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "163 {'loss': 19.730976104736328, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "164 {'loss': 17.71584701538086, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "165 {'loss': 41.09926986694336, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "166 {'loss': 18.26412010192871, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "167 {'loss': 19.862524032592773, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "168 {'loss': 39.613685607910156, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "169 {'loss': 49.460514068603516, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "170 {'loss': 49.427696228027344, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "171 {'loss': 19.551668167114258, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "172 {'loss': 49.357608795166016, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "173 {'loss': 18.22847557067871, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "174 {'loss': 21.915943145751953, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "175 {'loss': 19.817598342895508, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "176 {'loss': 6.8995795249938965, 'reward': 0.41000000000000003, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "177 {'loss': 21.901765823364258, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "178 {'loss': 48.949947357177734, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "179 {'loss': 17.43594741821289, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "180 {'loss': 39.174888610839844, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "181 {'loss': 17.475494384765625, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "182 {'loss': 24.298715591430664, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "183 {'loss': 19.57896614074707, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "184 {'loss': 18.002483367919922, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "185 {'loss': 39.145626068115234, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "186 {'loss': 19.53624725341797, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "187 {'loss': 24.24217987060547, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "188 {'loss': 39.0560417175293, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "189 {'loss': 17.865398406982422, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "190 {'loss': 17.248783111572266, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "191 {'loss': 19.490882873535156, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "192 {'loss': 48.59614181518555, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "193 {'loss': 22.828378677368164, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "194 {'loss': 19.2889404296875, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "195 {'loss': 24.4860897064209, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "196 {'loss': 19.3951358795166, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "197 {'loss': 48.347312927246094, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "198 {'loss': 17.594064712524414, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "199 {'loss': 18.951478958129883, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "200 {'loss': 17.085922241210938, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode  200: Mean Reward (last 100 episodes) = 0.0041 ---\n",
      "Episode  200: reward=0.0000, length=10\n",
      "  Latest sampled rule: grandparent(X2, X2) :- parent(X2, X3), parent(X3, X3), parent(X6, X7), parent(X8, X9).\n",
      "201 {'loss': 48.12450408935547, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "202 {'loss': 31.65079689025879, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "203 {'loss': 19.079729080200195, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "204 {'loss': 47.92864990234375, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "205 {'loss': 31.490375518798828, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "206 {'loss': 17.38174057006836, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "207 {'loss': 38.23948287963867, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "208 {'loss': 47.63270568847656, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "209 {'loss': 18.873313903808594, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "210 {'loss': 47.46969985961914, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "211 {'loss': 37.99231719970703, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "212 {'loss': 18.70848846435547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "213 {'loss': 18.54397201538086, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "214 {'loss': 18.56232452392578, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "215 {'loss': 18.37885284423828, 'reward': 0.010000000000000009, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "216 {'loss': 18.59752082824707, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "217 {'loss': 37.13447570800781, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "218 {'loss': 18.870586395263672, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "219 {'loss': 18.31147575378418, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "220 {'loss': 36.86726760864258, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "221 {'loss': 20.40415382385254, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "222 {'loss': 18.061534881591797, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "223 {'loss': 18.25783348083496, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "224 {'loss': 18.925270080566406, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "225 {'loss': 45.76858139038086, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "226 {'loss': 18.041078567504883, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "227 {'loss': 18.584125518798828, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "228 {'loss': 18.18507957458496, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "229 {'loss': 45.24810028076172, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "230 {'loss': 45.525508880615234, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "231 {'loss': 45.39621353149414, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "232 {'loss': 35.608577728271484, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "233 {'loss': 35.47228240966797, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "234 {'loss': 20.207223892211914, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "235 {'loss': 15.229751586914062, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "236 {'loss': 17.75446891784668, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "237 {'loss': 17.01242446899414, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "238 {'loss': 15.562138557434082, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "239 {'loss': 17.078733444213867, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "240 {'loss': 44.06741714477539, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "241 {'loss': 16.584121704101562, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "242 {'loss': 16.000934600830078, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "243 {'loss': 17.213945388793945, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "244 {'loss': 15.84558391571045, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "245 {'loss': 16.523700714111328, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "246 {'loss': 14.772500991821289, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "247 {'loss': 16.592092514038086, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "248 {'loss': 34.12849426269531, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "249 {'loss': 33.089927673339844, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "250 {'loss': 42.454437255859375, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "251 {'loss': 15.31793212890625, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "252 {'loss': 32.546791076660156, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "253 {'loss': 20.816402435302734, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "254 {'loss': 41.66827392578125, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "255 {'loss': 15.802945137023926, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "256 {'loss': 17.73451042175293, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "257 {'loss': 31.094345092773438, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "258 {'loss': 40.799232482910156, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "259 {'loss': 20.442350387573242, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "260 {'loss': 32.204376220703125, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "261 {'loss': 14.498624801635742, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "262 {'loss': 15.774225234985352, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "263 {'loss': 39.56878662109375, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "264 {'loss': 15.381003379821777, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "265 {'loss': 20.388601303100586, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "266 {'loss': 14.25897216796875, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "267 {'loss': 14.853439331054688, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "268 {'loss': 12.447290420532227, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "269 {'loss': 14.078544616699219, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "270 {'loss': 37.70295333862305, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "271 {'loss': 37.410606384277344, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "272 {'loss': 11.257776260375977, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "273 {'loss': 12.464639663696289, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "274 {'loss': 36.46589279174805, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "275 {'loss': 12.884810447692871, 'reward': 0.2625, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "276 {'loss': 19.42436408996582, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "277 {'loss': 12.35861873626709, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "278 {'loss': 21.010089874267578, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "279 {'loss': 34.76571273803711, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "280 {'loss': 21.348569869995117, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "281 {'loss': 27.188373565673828, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "282 {'loss': 17.972536087036133, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "283 {'loss': 15.209733963012695, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "284 {'loss': 12.634435653686523, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "285 {'loss': 32.38589096069336, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "286 {'loss': 31.95404624938965, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "287 {'loss': 30.610300064086914, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "288 {'loss': 31.01715087890625, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "289 {'loss': 13.215532302856445, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "290 {'loss': 8.098871231079102, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "291 {'loss': 29.5502872467041, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "292 {'loss': 11.660999298095703, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "293 {'loss': 28.578540802001953, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "294 {'loss': 8.142030715942383, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "295 {'loss': 26.600313186645508, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "296 {'loss': 18.435176849365234, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "297 {'loss': 7.553738594055176, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "298 {'loss': 16.757761001586914, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "299 {'loss': 9.338361740112305, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "300 {'loss': 7.174578666687012, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode  300: Mean Reward (last 100 episodes) = 0.0027 ---\n",
      "Episode  300: reward=0.0000, length=8\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X0, X3).\n",
      "301 {'loss': 24.310840606689453, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "302 {'loss': 10.824373245239258, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "303 {'loss': 9.09296703338623, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "304 {'loss': 6.2003278732299805, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "305 {'loss': 22.136795043945312, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "306 {'loss': 7.44251012802124, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "307 {'loss': 4.4598846435546875, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "308 {'loss': 20.52511978149414, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "309 {'loss': 18.864959716796875, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "310 {'loss': 19.37334632873535, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "311 {'loss': 18.77300453186035, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "312 {'loss': 5.327325344085693, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "313 {'loss': 4.036037445068359, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "314 {'loss': 3.030935525894165, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "315 {'loss': 16.444889068603516, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "316 {'loss': 15.878046035766602, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "317 {'loss': 8.5491943359375, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "318 {'loss': 14.712471008300781, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "319 {'loss': 12.904973983764648, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "320 {'loss': 13.518070220947266, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "321 {'loss': 11.44762897491455, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "322 {'loss': 12.316431999206543, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "323 {'loss': 9.980167388916016, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "324 {'loss': 1.8199173212051392, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "325 {'loss': 5.2892255783081055, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "326 {'loss': 10.070223808288574, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "327 {'loss': 9.548892974853516, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "328 {'loss': 7.414069175720215, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "329 {'loss': 5.176573276519775, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "330 {'loss': 8.070466995239258, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "331 {'loss': 7.617212772369385, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "332 {'loss': 5.466802597045898, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "333 {'loss': 6.7443461418151855, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "334 {'loss': 5.655142784118652, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "335 {'loss': 5.957735061645508, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "336 {'loss': 4.305646896362305, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "337 {'loss': 5.264585494995117, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "338 {'loss': 4.948310852050781, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "339 {'loss': 4.650447845458984, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "340 {'loss': 1.7109724283218384, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "341 {'loss': 4.150073051452637, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "342 {'loss': 3.9407601356506348, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "343 {'loss': 6.863655090332031, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "344 {'loss': 2.3939011096954346, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "345 {'loss': 3.4789440631866455, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "346 {'loss': 8.095930099487305, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "347 {'loss': 3.360811710357666, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "348 {'loss': 3.200654983520508, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "349 {'loss': 3.1280646324157715, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "350 {'loss': 7.475712776184082, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "351 {'loss': 1.6351444721221924, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "352 {'loss': 1.9388288259506226, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "353 {'loss': 2.9376606941223145, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "354 {'loss': 1.328700065612793, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "355 {'loss': 2.8533926010131836, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "356 {'loss': 1.8490798473358154, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "357 {'loss': 2.7610416412353516, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "358 {'loss': 2.7113678455352783, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "359 {'loss': 1.366097092628479, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "360 {'loss': 2.4979047775268555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "361 {'loss': 2.568040132522583, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "362 {'loss': 2.524237632751465, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "363 {'loss': 0.8223769068717957, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "364 {'loss': 2.4356305599212646, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "365 {'loss': 3.282876491546631, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "366 {'loss': 2.601149559020996, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "367 {'loss': 0.2960182726383209, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "368 {'loss': 1.6422052383422852, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "369 {'loss': 1.506394863128662, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "370 {'loss': 2.2619242668151855, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "371 {'loss': 3.9302818775177, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "372 {'loss': 1.5861876010894775, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "373 {'loss': 2.198245048522949, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "374 {'loss': 2.169102191925049, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "375 {'loss': 0.8462156057357788, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "376 {'loss': 2.1195998191833496, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "377 {'loss': 1.184962272644043, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "378 {'loss': 1.4932773113250732, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "379 {'loss': 1.5351896286010742, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "380 {'loss': 1.9998326301574707, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "381 {'loss': 1.0820910930633545, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "382 {'loss': 0.9385164976119995, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "383 {'loss': 1.7626909017562866, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "384 {'loss': 6.717230796813965, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "385 {'loss': 1.8664772510528564, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "386 {'loss': 1.0170726776123047, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "387 {'loss': 5.9326171875, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "388 {'loss': 1.0300254821777344, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "389 {'loss': 1.8526126146316528, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "390 {'loss': 5.952507019042969, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "391 {'loss': 1.3663111925125122, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "392 {'loss': 5.257407188415527, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "393 {'loss': 1.8969147205352783, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "394 {'loss': 1.9576051235198975, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "395 {'loss': 0.7198002934455872, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "396 {'loss': 0.6537065505981445, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "397 {'loss': 0.739388644695282, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "398 {'loss': 2.092073440551758, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "399 {'loss': 1.0362001657485962, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "400 {'loss': 1.1894375085830688, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode  400: Mean Reward (last 100 episodes) = 0.0000 ---\n",
      "Episode  400: reward=0.0000, length=6\n",
      "  Latest sampled rule: grandparent(X6, X6) :- parent(X6, X6), parent(X6, X6), parent(X6, X7).\n",
      "401 {'loss': 0.8992473483085632, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "402 {'loss': 1.8937259912490845, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "403 {'loss': 2.1364049911499023, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "404 {'loss': 1.465154767036438, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "405 {'loss': 0.6587219834327698, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "406 {'loss': 1.1351653337478638, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "407 {'loss': 0.884637176990509, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "408 {'loss': 1.3694312572479248, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "409 {'loss': 1.1873242855072021, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "410 {'loss': 1.9055626392364502, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "411 {'loss': 0.6390380859375, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "412 {'loss': 1.8981298208236694, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "413 {'loss': 29.40157127380371, 'reward': 1.0125, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "414 {'loss': 29.688669204711914, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "415 {'loss': 1.8374488353729248, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "416 {'loss': 28.1384220123291, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "417 {'loss': 29.14913558959961, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "418 {'loss': 0.8076872825622559, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "419 {'loss': 26.078020095825195, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "420 {'loss': 2.520169496536255, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "421 {'loss': 25.002098083496094, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "422 {'loss': 25.476566314697266, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "423 {'loss': 3.132127285003662, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "424 {'loss': 3.3338608741760254, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "425 {'loss': 22.044984817504883, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "426 {'loss': 1.2691856622695923, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "427 {'loss': 20.63632583618164, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "428 {'loss': 3.9839625358581543, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "429 {'loss': 1.033698320388794, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "430 {'loss': 20.40055274963379, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "431 {'loss': 1.1914633512496948, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "432 {'loss': 2.1145341396331787, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "433 {'loss': 22.15215492248535, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "434 {'loss': 4.822040557861328, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "435 {'loss': 4.332674026489258, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "436 {'loss': 17.986127853393555, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "437 {'loss': 4.644464015960693, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "438 {'loss': 17.90211296081543, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "439 {'loss': 17.804229736328125, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "440 {'loss': 1.5063343048095703, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "441 {'loss': 3.0883231163024902, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "442 {'loss': 16.82374382019043, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "443 {'loss': 15.8602876663208, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "444 {'loss': 5.959571838378906, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "445 {'loss': 17.083925247192383, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "446 {'loss': 1.6341882944107056, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "447 {'loss': 17.54789161682129, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "448 {'loss': 1.0816843509674072, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "449 {'loss': 16.410615921020508, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "450 {'loss': 16.597869873046875, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "451 {'loss': 6.506831169128418, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "452 {'loss': 15.835504531860352, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "453 {'loss': 20.580337524414062, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "454 {'loss': 1.103554368019104, 'reward': 0.29571428571428576, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "455 {'loss': 2.345393419265747, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "456 {'loss': 16.308956146240234, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "457 {'loss': 14.956903457641602, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "458 {'loss': 15.701349258422852, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "459 {'loss': 0.7860649824142456, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "460 {'loss': 3.149602174758911, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "461 {'loss': 7.2702531814575195, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "462 {'loss': 15.33353042602539, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "463 {'loss': 20.223440170288086, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "464 {'loss': 7.929128646850586, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "465 {'loss': 3.3262834548950195, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "466 {'loss': 15.655632019042969, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "467 {'loss': 7.85385274887085, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "468 {'loss': 14.60919189453125, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "469 {'loss': 2.7536447048187256, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "470 {'loss': 15.54366397857666, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "471 {'loss': 15.673479080200195, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "472 {'loss': 14.751171112060547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "473 {'loss': 2.8213348388671875, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "474 {'loss': 2.450141191482544, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "475 {'loss': 3.950087070465088, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "476 {'loss': 7.783797264099121, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "477 {'loss': 7.689375400543213, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "478 {'loss': 3.897897481918335, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "479 {'loss': 19.389278411865234, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "480 {'loss': 14.476699829101562, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "481 {'loss': 2.077934980392456, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "482 {'loss': 2.1939125061035156, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "483 {'loss': 17.370746612548828, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "484 {'loss': 7.039287567138672, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "485 {'loss': 15.188087463378906, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "486 {'loss': 2.0015134811401367, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "487 {'loss': 6.792572021484375, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "488 {'loss': 19.453937530517578, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "489 {'loss': 19.38991355895996, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "490 {'loss': 2.10536527633667, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "491 {'loss': 19.65544891357422, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "492 {'loss': 15.69270133972168, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "493 {'loss': 2.5223588943481445, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "494 {'loss': 15.864934921264648, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "495 {'loss': 2.212256669998169, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "496 {'loss': 5.521275043487549, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "497 {'loss': 2.4634833335876465, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "498 {'loss': 15.52938461303711, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "499 {'loss': 15.835806846618652, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "500 {'loss': 1.4875633716583252, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode  500: Mean Reward (last 100 episodes) = 0.0131 ---\n",
      "Episode  500: reward=0.0000, length=10\n",
      "  Latest sampled rule: grandparent(X6, X6) :- parent(X2, X2), parent(X4, X2), parent(X6, X7), parent(X8, X6).\n",
      "501 {'loss': 19.448116302490234, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "502 {'loss': 16.08043670654297, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "503 {'loss': 15.897188186645508, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "504 {'loss': 15.695802688598633, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "505 {'loss': 14.503297805786133, 'reward': 0.2625, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "506 {'loss': 6.460391044616699, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "507 {'loss': 14.555316925048828, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "508 {'loss': 15.674150466918945, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "509 {'loss': 2.9374635219573975, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "510 {'loss': 18.823808670043945, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "511 {'loss': 18.884370803833008, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "512 {'loss': 1.8853862285614014, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "513 {'loss': 2.752373218536377, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "514 {'loss': 14.17630386352539, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "515 {'loss': 16.573253631591797, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "516 {'loss': 4.029246807098389, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "517 {'loss': 3.546867609024048, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "518 {'loss': 2.765061855316162, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "519 {'loss': 15.19772720336914, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "520 {'loss': 2.000714063644409, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "521 {'loss': 3.9085006713867188, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "522 {'loss': 14.500097274780273, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "523 {'loss': 6.526560306549072, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "524 {'loss': 19.163301467895508, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "525 {'loss': 7.148433208465576, 'reward': 0.898888888888889, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "526 {'loss': 6.4218268394470215, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "527 {'loss': 9.958173751831055, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "528 {'loss': 9.520647048950195, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "529 {'loss': 6.402838230133057, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "530 {'loss': 1.4967986345291138, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "531 {'loss': 14.698673248291016, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "532 {'loss': 6.449782371520996, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "533 {'loss': 6.698290824890137, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "534 {'loss': 14.2318696975708, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "535 {'loss': 1.3939069509506226, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "536 {'loss': 2.111288547515869, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "537 {'loss': 14.687610626220703, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "538 {'loss': 14.996786117553711, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "539 {'loss': 14.440757751464844, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "540 {'loss': 3.13025164604187, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "541 {'loss': 15.807991027832031, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "542 {'loss': 1.722569227218628, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "543 {'loss': 6.408255100250244, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "544 {'loss': 4.191928386688232, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "545 {'loss': 14.025091171264648, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "546 {'loss': 16.76605987548828, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "547 {'loss': 11.077898979187012, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "548 {'loss': 13.75897216796875, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "549 {'loss': 15.078149795532227, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "550 {'loss': 11.04720401763916, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "551 {'loss': 9.664016723632812, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "552 {'loss': 14.010149002075195, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "553 {'loss': 2.8115017414093018, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "554 {'loss': 2.466341972351074, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "555 {'loss': 2.4229633808135986, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "556 {'loss': 2.0489754676818848, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "557 {'loss': 14.868022918701172, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "558 {'loss': 9.288554191589355, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "559 {'loss': 18.661226272583008, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "560 {'loss': 14.098420143127441, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "561 {'loss': 15.386209487915039, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "562 {'loss': 15.904067993164062, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "563 {'loss': 5.747048377990723, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "564 {'loss': 4.130571365356445, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "565 {'loss': 15.871464729309082, 'reward': 0.010000000000000009, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "566 {'loss': 4.3098039627075195, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "567 {'loss': 15.970797538757324, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "568 {'loss': 4.171022415161133, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "569 {'loss': 5.340724468231201, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "570 {'loss': 10.169990539550781, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "571 {'loss': 11.920583724975586, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "572 {'loss': 15.188070297241211, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "573 {'loss': 5.841641902923584, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "574 {'loss': 2.663360118865967, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "575 {'loss': 2.8288402557373047, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "576 {'loss': 10.615945816040039, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "577 {'loss': 18.453174591064453, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "578 {'loss': 16.640613555908203, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "579 {'loss': 15.539406776428223, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "580 {'loss': 3.9433817863464355, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "581 {'loss': 18.090686798095703, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "582 {'loss': 5.5182366371154785, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "583 {'loss': 5.343672275543213, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "584 {'loss': 10.176934242248535, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "585 {'loss': 18.037649154663086, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "586 {'loss': 2.933911085128784, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "587 {'loss': 16.108272552490234, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "588 {'loss': 5.407634735107422, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "589 {'loss': 5.032661437988281, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "590 {'loss': 3.467906951904297, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "591 {'loss': 11.254354476928711, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "592 {'loss': 23.636871337890625, 'reward': 1.01, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "593 {'loss': 1.8054571151733398, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "594 {'loss': 2.173024892807007, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "595 {'loss': 17.005773544311523, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "596 {'loss': 2.115060329437256, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "597 {'loss': 2.935397148132324, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "598 {'loss': 1.126819372177124, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "599 {'loss': 2.467528820037842, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "600 {'loss': 1.3532575368881226, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode  600: Mean Reward (last 100 episodes) = 0.0218 ---\n",
      "Episode  600: reward=0.0000, length=10\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X0, X3).\n",
      "601 {'loss': 13.479593276977539, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "602 {'loss': 10.536161422729492, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "603 {'loss': 2.216437578201294, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "604 {'loss': 2.8907768726348877, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "605 {'loss': 1.5795884132385254, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "606 {'loss': 12.360347747802734, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "607 {'loss': 13.034071922302246, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "608 {'loss': 1.7895244359970093, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "609 {'loss': 18.35759925842285, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "610 {'loss': 4.129472732543945, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "611 {'loss': 2.001615524291992, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "612 {'loss': 16.058012008666992, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "613 {'loss': 3.878699541091919, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "614 {'loss': 13.371625900268555, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "615 {'loss': 18.268566131591797, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "616 {'loss': 12.523818016052246, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "617 {'loss': 13.21347713470459, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "618 {'loss': 16.571290969848633, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "619 {'loss': 10.346404075622559, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "620 {'loss': 1.7552448511123657, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "621 {'loss': 1.5651692152023315, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "622 {'loss': 10.546651840209961, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "623 {'loss': 2.2432901859283447, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "624 {'loss': 3.5161073207855225, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "625 {'loss': 11.927131652832031, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "626 {'loss': 1.9767460823059082, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "627 {'loss': 15.87641429901123, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "628 {'loss': 10.706296920776367, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "629 {'loss': 15.76017951965332, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "630 {'loss': 1.1372668743133545, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "631 {'loss': 1.5911763906478882, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "632 {'loss': 3.785365343093872, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "633 {'loss': 2.860051155090332, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "634 {'loss': 1.646540880203247, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "635 {'loss': 16.858661651611328, 'reward': 0.61, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "636 {'loss': 2.68513822555542, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "637 {'loss': 12.401496887207031, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "638 {'loss': 16.287813186645508, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "639 {'loss': 10.889830589294434, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "640 {'loss': 15.49219036102295, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "641 {'loss': 1.707846999168396, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "642 {'loss': 2.5034117698669434, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "643 {'loss': 13.569336891174316, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "644 {'loss': 3.867356061935425, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "645 {'loss': 7.480198860168457, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "646 {'loss': 4.476150989532471, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "647 {'loss': 15.169620513916016, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "648 {'loss': 3.925727367401123, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "649 {'loss': 2.0615649223327637, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "650 {'loss': 4.709737300872803, 'reward': 0.7372727272727273, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "651 {'loss': 2.278428554534912, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "652 {'loss': 2.0352139472961426, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "653 {'loss': 15.59811782836914, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "654 {'loss': 7.273111820220947, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "655 {'loss': 7.306558609008789, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "656 {'loss': 2.965491533279419, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "657 {'loss': 14.299590110778809, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "658 {'loss': 9.282126426696777, 'reward': 0.29571428571428576, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "659 {'loss': 14.988005638122559, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "660 {'loss': 4.1550469398498535, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "661 {'loss': 12.9595365524292, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "662 {'loss': 15.171614646911621, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "663 {'loss': 14.308698654174805, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "664 {'loss': 1.7745152711868286, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "665 {'loss': 2.224078893661499, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "666 {'loss': 2.4062626361846924, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "667 {'loss': 1.2595769166946411, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "668 {'loss': 1.7136704921722412, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "669 {'loss': 14.999346733093262, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "670 {'loss': 1.589034914970398, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "671 {'loss': 11.84271240234375, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "672 {'loss': 15.295005798339844, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "673 {'loss': 2.7557177543640137, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "674 {'loss': 15.548669815063477, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "675 {'loss': 0.4547424912452698, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "676 {'loss': 4.106679439544678, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "677 {'loss': 1.2491486072540283, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "678 {'loss': 3.617093563079834, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "679 {'loss': 6.2034382820129395, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "680 {'loss': 3.908397912979126, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "681 {'loss': 7.436128616333008, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "682 {'loss': 1.9406394958496094, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "683 {'loss': 14.808926582336426, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "684 {'loss': 2.5087974071502686, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "685 {'loss': 1.4228813648223877, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "686 {'loss': 18.002363204956055, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "687 {'loss': 0.8647543787956238, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "688 {'loss': 10.258520126342773, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "689 {'loss': 3.2617859840393066, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "690 {'loss': 1.5641839504241943, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "691 {'loss': 1.3028372526168823, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "692 {'loss': 10.960516929626465, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "693 {'loss': 1.6150038242340088, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "694 {'loss': 5.60161018371582, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "695 {'loss': 13.001701354980469, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "696 {'loss': 16.26226043701172, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "697 {'loss': 13.994674682617188, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "698 {'loss': 2.006743907928467, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "699 {'loss': 16.18675994873047, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "700 {'loss': 3.337414264678955, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode  700: Mean Reward (last 100 episodes) = 0.0164 ---\n",
      "Episode  700: reward=0.0000, length=4\n",
      "  Latest sampled rule: grandparent(X2, X2) :- parent(X2, X3), parent(X4, X5).\n",
      "701 {'loss': 6.909853935241699, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "702 {'loss': 2.218308687210083, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "703 {'loss': 13.05297565460205, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "704 {'loss': 10.462034225463867, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "705 {'loss': 17.131450653076172, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "706 {'loss': 3.6672630310058594, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "707 {'loss': 15.66629695892334, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "708 {'loss': 1.552215814590454, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "709 {'loss': 16.922393798828125, 'reward': 0.61, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "710 {'loss': 15.148204803466797, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "711 {'loss': 12.866900444030762, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "712 {'loss': 3.9399330615997314, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "713 {'loss': 1.2545897960662842, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "714 {'loss': 14.69588851928711, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "715 {'loss': 1.4565930366516113, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "716 {'loss': 15.424711227416992, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "717 {'loss': 2.258927822113037, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "718 {'loss': 4.327241897583008, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "719 {'loss': 0.7463932633399963, 'reward': 0.29821428571428577, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "720 {'loss': 2.90474534034729, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "721 {'loss': 12.597610473632812, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "722 {'loss': 14.321065902709961, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "723 {'loss': 7.117790222167969, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "724 {'loss': 1.9698097705841064, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "725 {'loss': 4.2050323486328125, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "726 {'loss': 3.913156032562256, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "727 {'loss': 11.993831634521484, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "728 {'loss': 0.6113516688346863, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "729 {'loss': 9.54401969909668, 'reward': 0.7372727272727273, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "730 {'loss': 11.755797386169434, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "731 {'loss': 6.647282600402832, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "732 {'loss': 1.63204026222229, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "733 {'loss': 3.790846824645996, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "734 {'loss': 2.599972724914551, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "735 {'loss': 1.5435340404510498, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "736 {'loss': 10.638278007507324, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "737 {'loss': 3.871962785720825, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "738 {'loss': 4.061945915222168, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "739 {'loss': 3.915297269821167, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "740 {'loss': 7.4791975021362305, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "741 {'loss': 3.4569287300109863, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "742 {'loss': 8.774142265319824, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "743 {'loss': 2.0438952445983887, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "744 {'loss': 1.8717021942138672, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "745 {'loss': 1.6103066205978394, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "746 {'loss': 2.0465288162231445, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "747 {'loss': 14.341297149658203, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "748 {'loss': 1.2778823375701904, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "749 {'loss': 8.767448425292969, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "750 {'loss': 1.5593878030776978, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "751 {'loss': 13.483415603637695, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "752 {'loss': 16.16967010498047, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "753 {'loss': 16.445371627807617, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "754 {'loss': 16.991588592529297, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "755 {'loss': 14.203533172607422, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "756 {'loss': 17.531299591064453, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "757 {'loss': 4.806012153625488, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "758 {'loss': 2.4645276069641113, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "759 {'loss': 4.243076801300049, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "760 {'loss': 8.701778411865234, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "761 {'loss': 1.3068315982818604, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "762 {'loss': 13.93460464477539, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "763 {'loss': 0.19134144484996796, 'reward': 0.3397727272727272, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "764 {'loss': 0.9524396657943726, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "765 {'loss': 14.481392860412598, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "766 {'loss': 4.576258659362793, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "767 {'loss': 9.51385498046875, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "768 {'loss': 3.1225810050964355, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "769 {'loss': 2.1336076259613037, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "770 {'loss': 2.1991055011749268, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "771 {'loss': 0.8973097801208496, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "772 {'loss': 3.1695783138275146, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "773 {'loss': 8.273700714111328, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "774 {'loss': 12.223861694335938, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "775 {'loss': 3.039376735687256, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "776 {'loss': 3.0398964881896973, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "777 {'loss': 2.918820858001709, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "778 {'loss': 1.9696593284606934, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "779 {'loss': 8.745622634887695, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "780 {'loss': 0.7537561058998108, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "781 {'loss': 10.747647285461426, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "782 {'loss': 0.4645131230354309, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "783 {'loss': 5.5234832763671875, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "784 {'loss': 2.0288748741149902, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "785 {'loss': 8.551207542419434, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "786 {'loss': 1.3330310583114624, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "787 {'loss': 5.43626594543457, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "788 {'loss': 8.487342834472656, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "789 {'loss': 6.204396724700928, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "790 {'loss': 10.22240161895752, 'reward': 0.3372727272727273, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "791 {'loss': 5.119284629821777, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "792 {'loss': 6.916516304016113, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "793 {'loss': 16.129106521606445, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "794 {'loss': 8.126968383789062, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "795 {'loss': 1.4922302961349487, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "796 {'loss': 4.548720359802246, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "797 {'loss': 2.267735004425049, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "798 {'loss': 1.208876132965088, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "799 {'loss': 6.031986236572266, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "800 {'loss': 0.9040031433105469, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode  800: Mean Reward (last 100 episodes) = 0.0232 ---\n",
      "Episode  800: reward=0.0000, length=5\n",
      "  Latest sampled rule: grandparent(X0, X6) :- parent(X0, X0), parent(X0, X0), parent(X6, X7), parent(X8, X9).\n",
      "801 {'loss': 5.535539627075195, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "802 {'loss': 1.1849164962768555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "803 {'loss': 2.7698988914489746, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "804 {'loss': 1.5406842231750488, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "805 {'loss': 15.319520950317383, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "806 {'loss': 13.392749786376953, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "807 {'loss': 1.8632147312164307, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "808 {'loss': 0.6119841933250427, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "809 {'loss': 0.4755297005176544, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "810 {'loss': 6.804131984710693, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "811 {'loss': 4.887180805206299, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "812 {'loss': 3.6519200801849365, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "813 {'loss': 16.55922508239746, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "814 {'loss': 6.974430561065674, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "815 {'loss': 5.8964128494262695, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "816 {'loss': 1.8871805667877197, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "817 {'loss': 12.682048797607422, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "818 {'loss': 11.99608039855957, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "819 {'loss': 7.0329437255859375, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "820 {'loss': 7.189262866973877, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "821 {'loss': 0.9148493409156799, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "822 {'loss': 2.216871500015259, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "823 {'loss': 9.60810661315918, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "824 {'loss': 9.828454971313477, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "825 {'loss': 6.59116268157959, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "826 {'loss': 10.187366485595703, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "827 {'loss': 1.5596246719360352, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "828 {'loss': 4.050449371337891, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "829 {'loss': 1.6989628076553345, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "830 {'loss': 14.846502304077148, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "831 {'loss': 1.67866849899292, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "832 {'loss': 12.956427574157715, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "833 {'loss': 2.8558402061462402, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "834 {'loss': 2.4155216217041016, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "835 {'loss': 9.101798057556152, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "836 {'loss': 1.7980610132217407, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "837 {'loss': 6.3815202713012695, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "838 {'loss': 1.53660249710083, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "839 {'loss': 7.067121505737305, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "840 {'loss': 2.6720352172851562, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "841 {'loss': 6.413912773132324, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "842 {'loss': 8.654810905456543, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "843 {'loss': 14.676705360412598, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "844 {'loss': 3.8083064556121826, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "845 {'loss': 7.038772106170654, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "846 {'loss': 8.50985336303711, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "847 {'loss': 8.947345733642578, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "848 {'loss': 8.374615669250488, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "849 {'loss': 0.8535809516906738, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "850 {'loss': 2.669058084487915, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "851 {'loss': 1.2494487762451172, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "852 {'loss': 8.936712265014648, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "853 {'loss': 9.587858200073242, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "854 {'loss': 3.6833927631378174, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "855 {'loss': 3.0713460445404053, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "856 {'loss': 1.9084508419036865, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "857 {'loss': 3.364384174346924, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "858 {'loss': 3.3299155235290527, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "859 {'loss': 4.745689392089844, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "860 {'loss': 10.71098804473877, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "861 {'loss': 14.027311325073242, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "862 {'loss': 7.499739646911621, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "863 {'loss': 7.749494552612305, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "864 {'loss': 2.946335792541504, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "865 {'loss': 1.1778209209442139, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "866 {'loss': 16.010438919067383, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "867 {'loss': 8.43043327331543, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "868 {'loss': 2.4866831302642822, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "869 {'loss': 0.7160619497299194, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "870 {'loss': 4.782991886138916, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "871 {'loss': 9.88701057434082, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "872 {'loss': 1.5194683074951172, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "873 {'loss': 8.854875564575195, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "874 {'loss': 14.55752182006836, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "875 {'loss': 1.593429684638977, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "876 {'loss': 2.1628599166870117, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "877 {'loss': 8.141348838806152, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "878 {'loss': 14.249688148498535, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "879 {'loss': 1.1224658489227295, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "880 {'loss': 17.012165069580078, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "881 {'loss': 1.9221765995025635, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "882 {'loss': 11.448742866516113, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "883 {'loss': 8.64029598236084, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "884 {'loss': 13.280226707458496, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "885 {'loss': 1.9933626651763916, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "886 {'loss': 0.5497022271156311, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "887 {'loss': 1.4469856023788452, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "888 {'loss': 2.194225311279297, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "889 {'loss': 13.523529052734375, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "890 {'loss': 1.230180025100708, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "891 {'loss': 1.9519245624542236, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "892 {'loss': 1.4764033555984497, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "893 {'loss': 16.98373794555664, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "894 {'loss': 7.84356689453125, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "895 {'loss': 1.8185296058654785, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "896 {'loss': 1.7413276433944702, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "897 {'loss': 2.8964385986328125, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "898 {'loss': 11.441835403442383, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "899 {'loss': 0.8446663022041321, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "900 {'loss': 5.666913032531738, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "\n",
      "--- Episode  900: Mean Reward (last 100 episodes) = 0.0000 ---\n",
      "Episode  900: reward=0.0000, length=5\n",
      "  Latest sampled rule: grandparent(X1, X1) :- parent(X2, X1), parent(X6, X5), parent(X6, X7).\n",
      "901 {'loss': 14.846109390258789, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "902 {'loss': 6.393586158752441, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "903 {'loss': 1.6649900674819946, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "904 {'loss': 1.2804858684539795, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "905 {'loss': 11.33586597442627, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "906 {'loss': 2.2325851917266846, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "907 {'loss': 6.826402187347412, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "908 {'loss': 13.773677825927734, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "909 {'loss': 1.384169340133667, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "910 {'loss': 7.859088897705078, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "911 {'loss': 0.6414481401443481, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "912 {'loss': 1.2177404165267944, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "913 {'loss': 1.563084363937378, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "914 {'loss': 16.920103073120117, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "915 {'loss': 5.188947677612305, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "916 {'loss': 16.254623413085938, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "917 {'loss': 1.4634134769439697, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "918 {'loss': 1.2164489030838013, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "919 {'loss': 1.655653476715088, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "920 {'loss': 0.6536491513252258, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "921 {'loss': 13.998852729797363, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "922 {'loss': 1.5652605295181274, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "923 {'loss': 1.4891526699066162, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "924 {'loss': 16.783748626708984, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "925 {'loss': 1.7233238220214844, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "926 {'loss': 1.6074295043945312, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "927 {'loss': 1.1534075736999512, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "928 {'loss': 1.0101912021636963, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "929 {'loss': 5.745881080627441, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "930 {'loss': 17.024377822875977, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "931 {'loss': 1.642423391342163, 'reward': 0.21000000000000002, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "932 {'loss': 7.741086959838867, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "933 {'loss': 13.724449157714844, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "934 {'loss': 7.296494483947754, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "935 {'loss': 1.3530329465866089, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "936 {'loss': 1.9943327903747559, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "937 {'loss': 0.836199939250946, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "938 {'loss': 1.0660984516143799, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "939 {'loss': 8.182596206665039, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "940 {'loss': 2.1132264137268066, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "941 {'loss': 0.8089975118637085, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "942 {'loss': 1.138405442237854, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "943 {'loss': 1.1135212182998657, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "944 {'loss': 1.280712366104126, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "945 {'loss': 1.8217750787734985, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "946 {'loss': 10.929630279541016, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "947 {'loss': 4.76171875, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "948 {'loss': 1.8130613565444946, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "949 {'loss': 17.249298095703125, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "950 {'loss': 1.7583333253860474, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "951 {'loss': 8.31445598602295, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "952 {'loss': 1.9204912185668945, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "953 {'loss': 5.160263538360596, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "954 {'loss': 16.50420570373535, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "955 {'loss': 1.2752000093460083, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "956 {'loss': 11.36848258972168, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "957 {'loss': 16.514047622680664, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "958 {'loss': 16.933950424194336, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "959 {'loss': 11.06534194946289, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "960 {'loss': 16.667011260986328, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "961 {'loss': 11.04847526550293, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "962 {'loss': 2.7812154293060303, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "963 {'loss': 1.9892501831054688, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "964 {'loss': 1.3083242177963257, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "965 {'loss': 11.709157943725586, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "966 {'loss': 2.7312021255493164, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "967 {'loss': 13.339707374572754, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "968 {'loss': 0.8280982971191406, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "969 {'loss': 11.973180770874023, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "970 {'loss': 1.1766806840896606, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "971 {'loss': 5.31809139251709, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "972 {'loss': 1.106955885887146, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "973 {'loss': 1.3016160726547241, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "974 {'loss': 1.6399093866348267, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "975 {'loss': 2.1202802658081055, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "976 {'loss': 13.241010665893555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "977 {'loss': 15.34731674194336, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "978 {'loss': 5.318317413330078, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "979 {'loss': 6.1897993087768555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "980 {'loss': 16.31309700012207, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "981 {'loss': 13.397369384765625, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "982 {'loss': 5.549843788146973, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "983 {'loss': 15.484341621398926, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "984 {'loss': 8.399550437927246, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "985 {'loss': 16.171531677246094, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "986 {'loss': 7.716209411621094, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "987 {'loss': 2.5897228717803955, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "988 {'loss': 9.975430488586426, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "989 {'loss': 8.494081497192383, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "990 {'loss': 3.1051597595214844, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "991 {'loss': 2.1975574493408203, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "992 {'loss': 2.7014241218566895, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "993 {'loss': 3.591792345046997, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "994 {'loss': 4.711550235748291, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "995 {'loss': 7.001733779907227, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "996 {'loss': 1.77457594871521, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "997 {'loss': 12.661399841308594, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "998 {'loss': 1.689637541770935, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "999 {'loss': 9.905487060546875, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1000 {'loss': 6.689260959625244, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "\n",
      "--- Episode 1000: Mean Reward (last 100 episodes) = 0.0021 ---\n",
      "Episode 1000: reward=0.0000, length=10\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X2, X0), parent(X4, X5).\n",
      "1001 {'loss': 11.65165901184082, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1002 {'loss': 2.4698548316955566, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1003 {'loss': 2.3125901222229004, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1004 {'loss': 2.0312445163726807, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1005 {'loss': 15.577178955078125, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1006 {'loss': 4.1858601570129395, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1007 {'loss': 10.357263565063477, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1008 {'loss': 1.785390853881836, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1009 {'loss': 6.835080146789551, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1010 {'loss': 13.765172004699707, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1011 {'loss': 15.227629661560059, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1012 {'loss': 1.3973567485809326, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1013 {'loss': 0.5207557678222656, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1014 {'loss': 12.833616256713867, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1015 {'loss': 15.47049617767334, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1016 {'loss': 2.3420517444610596, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1017 {'loss': 3.1043643951416016, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1018 {'loss': 8.055635452270508, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1019 {'loss': 2.3260140419006348, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1020 {'loss': 2.2016894817352295, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1021 {'loss': 14.916542053222656, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1022 {'loss': 14.840490341186523, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1023 {'loss': 15.795462608337402, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1024 {'loss': 2.1937708854675293, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1025 {'loss': 2.0086669921875, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1026 {'loss': 7.25931978225708, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1027 {'loss': 3.066556930541992, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1028 {'loss': 1.2847073078155518, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1029 {'loss': 3.9329864978790283, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1030 {'loss': 8.010297775268555, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1031 {'loss': 1.670467734336853, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1032 {'loss': 2.1201400756835938, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1033 {'loss': 10.960360527038574, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1034 {'loss': 4.101574897766113, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1035 {'loss': 1.9991674423217773, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1036 {'loss': 3.0045602321624756, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1037 {'loss': 1.536788821220398, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1038 {'loss': 1.9462087154388428, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1039 {'loss': 14.287652969360352, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1040 {'loss': 1.241287350654602, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1041 {'loss': 15.502923965454102, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1042 {'loss': 1.8105387687683105, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1043 {'loss': 2.124126434326172, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1044 {'loss': 4.523422718048096, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1045 {'loss': 12.568000793457031, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1046 {'loss': 0.7227916121482849, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1047 {'loss': 1.7752676010131836, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1048 {'loss': 2.6337342262268066, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1049 {'loss': 7.294805526733398, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1050 {'loss': 1.5302294492721558, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1051 {'loss': 1.3097654581069946, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1052 {'loss': 1.6122710704803467, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1053 {'loss': 10.95962905883789, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1054 {'loss': 1.5484867095947266, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1055 {'loss': 7.263649940490723, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1056 {'loss': 7.337119102478027, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1057 {'loss': 2.151590585708618, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1058 {'loss': 16.026609420776367, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1059 {'loss': 7.396950721740723, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1060 {'loss': 1.5584648847579956, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1061 {'loss': 17.01756477355957, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1062 {'loss': 16.438091278076172, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1063 {'loss': 7.187048435211182, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1064 {'loss': 0.597260057926178, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1065 {'loss': 0.7390797734260559, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1066 {'loss': 0.46354466676712036, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1067 {'loss': 6.857816219329834, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1068 {'loss': 10.963926315307617, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1069 {'loss': 5.825466156005859, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1070 {'loss': 7.325405597686768, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1071 {'loss': 1.7284687757492065, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1072 {'loss': 9.772438049316406, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1073 {'loss': 6.858170032501221, 'reward': 0.7397727272727272, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1074 {'loss': 9.164759635925293, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1075 {'loss': 9.126908302307129, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1076 {'loss': 3.1428720951080322, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1077 {'loss': 2.8486404418945312, 'reward': 0.20999999999999996, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1078 {'loss': 8.677762985229492, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1079 {'loss': 3.6294937133789062, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1080 {'loss': 12.676348686218262, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1081 {'loss': 1.8071731328964233, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1082 {'loss': 2.132734537124634, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1083 {'loss': 10.912775039672852, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1084 {'loss': 3.087574005126953, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1085 {'loss': 0.7944372892379761, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1086 {'loss': 8.484966278076172, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1087 {'loss': 1.6443060636520386, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1088 {'loss': 14.6304292678833, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1089 {'loss': 7.142670631408691, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1090 {'loss': 2.086455821990967, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1091 {'loss': 1.0325275659561157, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1092 {'loss': 2.0066871643066406, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1093 {'loss': 12.351510047912598, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1094 {'loss': 1.9538891315460205, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1095 {'loss': 12.166470527648926, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1096 {'loss': 6.987728118896484, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1097 {'loss': 9.107539176940918, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1098 {'loss': 1.6653934717178345, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1099 {'loss': 14.16675090789795, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1100 {'loss': 1.5190904140472412, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode 1100: Mean Reward (last 100 episodes) = 0.0095 ---\n",
      "Episode 1100: reward=0.0000, length=10\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X2, X2), parent(X0, X5).\n",
      "1101 {'loss': 6.676403522491455, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1102 {'loss': 6.852516174316406, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1103 {'loss': 1.9912081956863403, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1104 {'loss': 3.284287929534912, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1105 {'loss': 1.5380842685699463, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1106 {'loss': 11.569446563720703, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1107 {'loss': 2.517029285430908, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1108 {'loss': 2.3559861183166504, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1109 {'loss': 2.167116165161133, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1110 {'loss': 1.8574501276016235, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1111 {'loss': 4.780309677124023, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1112 {'loss': 3.384458541870117, 'reward': 0.3372727272727273, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1113 {'loss': 10.601386070251465, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1114 {'loss': 12.170604705810547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1115 {'loss': 0.9492612481117249, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1116 {'loss': 11.800392150878906, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1117 {'loss': 10.035868644714355, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1118 {'loss': 0.8226359486579895, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1119 {'loss': 1.8816436529159546, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1120 {'loss': 1.124448537826538, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1121 {'loss': 5.929737567901611, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1122 {'loss': 7.502789497375488, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1123 {'loss': 12.588541030883789, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1124 {'loss': 1.567646861076355, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1125 {'loss': 15.082462310791016, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1126 {'loss': 1.7000679969787598, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1127 {'loss': 1.7048687934875488, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1128 {'loss': 13.096095085144043, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1129 {'loss': 7.465710639953613, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1130 {'loss': 1.7342051267623901, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1131 {'loss': 8.477338790893555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1132 {'loss': 1.6157773733139038, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1133 {'loss': 8.407535552978516, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1134 {'loss': 10.492871284484863, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1135 {'loss': 14.232895851135254, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1136 {'loss': 1.7258100509643555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1137 {'loss': 10.48574447631836, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1138 {'loss': 11.93168830871582, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1139 {'loss': 9.705856323242188, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1140 {'loss': 1.9316720962524414, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1141 {'loss': 12.263331413269043, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1142 {'loss': 1.9564037322998047, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1143 {'loss': 14.087373733520508, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1144 {'loss': 12.517951965332031, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1145 {'loss': 1.7347586154937744, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1146 {'loss': 2.706050157546997, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1147 {'loss': 0.7557483315467834, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1148 {'loss': 13.80235481262207, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1149 {'loss': 6.8953537940979, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1150 {'loss': 2.1370348930358887, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1151 {'loss': 8.453763008117676, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1152 {'loss': 13.459620475769043, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1153 {'loss': 2.162642240524292, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1154 {'loss': 6.6939287185668945, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1155 {'loss': 2.041961193084717, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1156 {'loss': 4.695794105529785, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1157 {'loss': 5.440990447998047, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1158 {'loss': 2.115629196166992, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1159 {'loss': 7.652843475341797, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1160 {'loss': 5.286848068237305, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1161 {'loss': 5.865206241607666, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1162 {'loss': 14.475436210632324, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1163 {'loss': 0.5175739526748657, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1164 {'loss': 7.988259315490723, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1165 {'loss': 6.382271766662598, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1166 {'loss': 6.861122131347656, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1167 {'loss': 4.100773334503174, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1168 {'loss': 2.035104274749756, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1169 {'loss': 1.722479224205017, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1170 {'loss': 10.377105712890625, 'reward': 0.49888888888888894, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1171 {'loss': 6.969346046447754, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1172 {'loss': 1.9427404403686523, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1173 {'loss': 2.1835548877716064, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1174 {'loss': 5.074979782104492, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1175 {'loss': 1.898622751235962, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1176 {'loss': 1.7108724117279053, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1177 {'loss': 9.496822357177734, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1178 {'loss': 8.904569625854492, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1179 {'loss': 2.0274014472961426, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1180 {'loss': 0.6079303026199341, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1181 {'loss': 1.3596956729888916, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1182 {'loss': 2.5514814853668213, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1183 {'loss': 14.332344055175781, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1184 {'loss': 1.3196195363998413, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1185 {'loss': 1.6640545129776, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1186 {'loss': 1.599504828453064, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1187 {'loss': 8.768860816955566, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1188 {'loss': 1.5704940557479858, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1189 {'loss': 1.579233169555664, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1190 {'loss': 1.1258041858673096, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1191 {'loss': 1.459817886352539, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1192 {'loss': 10.031980514526367, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1193 {'loss': 14.77684211730957, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1194 {'loss': 1.9233474731445312, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1195 {'loss': 8.663619041442871, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1196 {'loss': 2.1456949710845947, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1197 {'loss': 1.436523199081421, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1198 {'loss': 1.3699817657470703, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1199 {'loss': 1.3360035419464111, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1200 {'loss': 1.3841774463653564, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode 1200: Mean Reward (last 100 episodes) = 0.0084 ---\n",
      "Episode 1200: reward=0.0000, length=10\n",
      "  Latest sampled rule: grandparent(X2, X2) :- parent(X2, X2), parent(X2, X5), parent(X6, X7), parent(X8, X9).\n",
      "1201 {'loss': 2.217118263244629, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1202 {'loss': 3.333141326904297, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1203 {'loss': 6.80014181137085, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1204 {'loss': 1.2421574592590332, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1205 {'loss': 2.174577236175537, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1206 {'loss': 15.633672714233398, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1207 {'loss': 0.7705360651016235, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1208 {'loss': 0.4726018011569977, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1209 {'loss': 5.569027423858643, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1210 {'loss': 1.1636711359024048, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1211 {'loss': 0.997519314289093, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1212 {'loss': 9.893343925476074, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1213 {'loss': 1.4724030494689941, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1214 {'loss': 15.276703834533691, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1215 {'loss': 7.081135272979736, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1216 {'loss': 2.7379953861236572, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1217 {'loss': 7.046051979064941, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1218 {'loss': 1.3065484762191772, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1219 {'loss': 1.5017094612121582, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1220 {'loss': 1.431823492050171, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1221 {'loss': 0.41489821672439575, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1222 {'loss': 11.76546859741211, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1223 {'loss': 0.47261613607406616, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1224 {'loss': 1.820111870765686, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1225 {'loss': 6.480654716491699, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1226 {'loss': 0.768100380897522, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1227 {'loss': 4.87469482421875, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1228 {'loss': 4.244060516357422, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1229 {'loss': 1.7967634201049805, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1230 {'loss': 7.234600067138672, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1231 {'loss': 9.031577110290527, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1232 {'loss': 4.664813041687012, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1233 {'loss': 0.7688303589820862, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1234 {'loss': 1.1869511604309082, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1235 {'loss': 12.247547149658203, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1236 {'loss': 0.9821917414665222, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1237 {'loss': 1.5753676891326904, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1238 {'loss': 1.5052855014801025, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1239 {'loss': 12.492833137512207, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1240 {'loss': 8.713855743408203, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1241 {'loss': 0.9461176991462708, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1242 {'loss': 14.390156745910645, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1243 {'loss': 1.227961540222168, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1244 {'loss': 15.832834243774414, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1245 {'loss': 1.3455924987792969, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1246 {'loss': 1.3689749240875244, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1247 {'loss': 1.5684795379638672, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1248 {'loss': 5.532356262207031, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1249 {'loss': 7.767053604125977, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1250 {'loss': 6.760988235473633, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1251 {'loss': 0.5815321207046509, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1252 {'loss': 9.970043182373047, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1253 {'loss': 1.2868419885635376, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1254 {'loss': 7.536341190338135, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1255 {'loss': 11.221431732177734, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1256 {'loss': 0.8193254470825195, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1257 {'loss': 1.0855159759521484, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1258 {'loss': 13.414392471313477, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1259 {'loss': 1.0734202861785889, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1260 {'loss': 2.5360732078552246, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1261 {'loss': 2.681644916534424, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1262 {'loss': 1.3705062866210938, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1263 {'loss': 9.6761474609375, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1264 {'loss': 4.494085311889648, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1265 {'loss': 10.593535423278809, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1266 {'loss': 9.24820613861084, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1267 {'loss': 4.2382330894470215, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1268 {'loss': 2.4578964710235596, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1269 {'loss': 1.6750924587249756, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1270 {'loss': 12.07247543334961, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1271 {'loss': 0.9510614275932312, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1272 {'loss': 7.39217472076416, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1273 {'loss': 1.9671539068222046, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1274 {'loss': 7.426288604736328, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1275 {'loss': 1.5603184700012207, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1276 {'loss': 1.52903413772583, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1277 {'loss': 7.968569755554199, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1278 {'loss': 1.452671766281128, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1279 {'loss': 0.9426571726799011, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1280 {'loss': 11.552274703979492, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1281 {'loss': 1.4086105823516846, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1282 {'loss': 6.096769332885742, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1283 {'loss': 1.3349435329437256, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1284 {'loss': 9.848020553588867, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1285 {'loss': 10.043113708496094, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1286 {'loss': 8.171337127685547, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1287 {'loss': 2.6303470134735107, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1288 {'loss': 1.3099709749221802, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1289 {'loss': 5.849240779876709, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1290 {'loss': 11.753275871276855, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1291 {'loss': 0.972607433795929, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1292 {'loss': 1.323358178138733, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1293 {'loss': 1.35115647315979, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1294 {'loss': 4.6665167808532715, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1295 {'loss': 1.655590295791626, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1296 {'loss': 6.918653964996338, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1297 {'loss': 12.570422172546387, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1298 {'loss': 3.4088127613067627, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1299 {'loss': 2.043644428253174, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1300 {'loss': 6.81044864654541, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "\n",
      "--- Episode 1300: Mean Reward (last 100 episodes) = 0.0000 ---\n",
      "Episode 1300: reward=0.0000, length=7\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X2, X0).\n",
      "1301 {'loss': 6.219554901123047, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1302 {'loss': 4.527004718780518, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1303 {'loss': 0.7244444489479065, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1304 {'loss': 13.530085563659668, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1305 {'loss': 8.887816429138184, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1306 {'loss': 5.485403537750244, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1307 {'loss': 1.5920230150222778, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1308 {'loss': 1.4589790105819702, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1309 {'loss': 4.392244338989258, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1310 {'loss': 1.194526195526123, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1311 {'loss': 11.990662574768066, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1312 {'loss': 1.5552523136138916, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1313 {'loss': 0.42146816849708557, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1314 {'loss': 4.122323989868164, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1315 {'loss': 3.5734684467315674, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1316 {'loss': 1.1625471115112305, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1317 {'loss': 0.6689202189445496, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1318 {'loss': 6.769068717956543, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1319 {'loss': 1.7024425268173218, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1320 {'loss': 1.4802809953689575, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1321 {'loss': 1.4216874837875366, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1322 {'loss': 6.641167163848877, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1323 {'loss': 1.4802441596984863, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1324 {'loss': 9.54273796081543, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1325 {'loss': 1.5029847621917725, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1326 {'loss': 1.4523926973342896, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1327 {'loss': 8.105476379394531, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1328 {'loss': 12.04269027709961, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1329 {'loss': 1.1443756818771362, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1330 {'loss': 1.1839468479156494, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1331 {'loss': 1.8780430555343628, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1332 {'loss': 8.96297836303711, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1333 {'loss': 8.270458221435547, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1334 {'loss': 3.1699934005737305, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1335 {'loss': 8.130386352539062, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1336 {'loss': 1.2089965343475342, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1337 {'loss': 1.5145498514175415, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1338 {'loss': 14.765019416809082, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1339 {'loss': 8.332785606384277, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1340 {'loss': 1.4129164218902588, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1341 {'loss': 6.277862071990967, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1342 {'loss': 11.801939964294434, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1343 {'loss': 2.7448158264160156, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1344 {'loss': 9.581489562988281, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1345 {'loss': 12.327857971191406, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1346 {'loss': 8.94873332977295, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1347 {'loss': 4.20683479309082, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1348 {'loss': 1.8158544301986694, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1349 {'loss': 13.29702091217041, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1350 {'loss': 2.031449317932129, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1351 {'loss': 8.92856216430664, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1352 {'loss': 4.194243431091309, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1353 {'loss': 1.651212453842163, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1354 {'loss': 1.8293734788894653, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1355 {'loss': 2.2665441036224365, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1356 {'loss': 8.058996200561523, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1357 {'loss': 3.4779932498931885, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1358 {'loss': 8.645477294921875, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1359 {'loss': 11.51446533203125, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1360 {'loss': 11.49240493774414, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1361 {'loss': 5.102671146392822, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1362 {'loss': 1.5427298545837402, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1363 {'loss': 1.481043815612793, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1364 {'loss': 1.460510492324829, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1365 {'loss': 7.24254035949707, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1366 {'loss': 1.4688618183135986, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1367 {'loss': 1.8538247346878052, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1368 {'loss': 0.6701786518096924, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1369 {'loss': 1.4554312229156494, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1370 {'loss': 4.354129791259766, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1371 {'loss': 1.1941567659378052, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1372 {'loss': 0.9176018238067627, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1373 {'loss': 4.16963005065918, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1374 {'loss': 4.318037033081055, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1375 {'loss': 0.9158459305763245, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1376 {'loss': 3.9463295936584473, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1377 {'loss': 2.440873622894287, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1378 {'loss': 1.2241995334625244, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1379 {'loss': 1.9258166551589966, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1380 {'loss': 9.027301788330078, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1381 {'loss': 1.1758933067321777, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1382 {'loss': 6.416501045227051, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1383 {'loss': 2.162503480911255, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1384 {'loss': 7.112435340881348, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1385 {'loss': 14.695599555969238, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1386 {'loss': 1.1633868217468262, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1387 {'loss': 1.2725964784622192, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1388 {'loss': 1.1553916931152344, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1389 {'loss': 0.7782130241394043, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1390 {'loss': 0.9093512296676636, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1391 {'loss': 11.953862190246582, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1392 {'loss': 12.318538665771484, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1393 {'loss': 1.0280098915100098, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1394 {'loss': 9.40638256072998, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1395 {'loss': 1.1571449041366577, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1396 {'loss': 6.12493371963501, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1397 {'loss': 4.161226272583008, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1398 {'loss': 2.2499732971191406, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1399 {'loss': 2.4689106941223145, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1400 {'loss': 3.6950302124023438, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "\n",
      "--- Episode 1400: Mean Reward (last 100 episodes) = 0.0000 ---\n",
      "Episode 1400: reward=0.0000, length=4\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X2, X0).\n",
      "1401 {'loss': 1.0154591798782349, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1402 {'loss': 14.661025047302246, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1403 {'loss': 1.1307134628295898, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1404 {'loss': 1.6999644041061401, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1405 {'loss': 6.268399238586426, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1406 {'loss': 0.5285292863845825, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1407 {'loss': 1.2113054990768433, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1408 {'loss': 6.145900726318359, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1409 {'loss': 12.73656940460205, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1410 {'loss': 4.005121231079102, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1411 {'loss': 3.2764108180999756, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1412 {'loss': 1.2389016151428223, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1413 {'loss': 3.6157591342926025, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1414 {'loss': 2.2960619926452637, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1415 {'loss': 1.1478593349456787, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1416 {'loss': 1.343230962753296, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1417 {'loss': 0.8706833124160767, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1418 {'loss': 1.267382264137268, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1419 {'loss': 2.319814443588257, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1420 {'loss': 8.716962814331055, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1421 {'loss': 1.5969383716583252, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1422 {'loss': 2.0727574825286865, 'reward': 0.21250000000000002, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1423 {'loss': 0.5400987863540649, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1424 {'loss': 2.3953232765197754, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1425 {'loss': 10.909086227416992, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1426 {'loss': 0.8215223550796509, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1427 {'loss': 8.186225891113281, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1428 {'loss': 1.165123462677002, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1429 {'loss': 4.320622444152832, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1430 {'loss': 0.23954971134662628, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1431 {'loss': 0.9018293619155884, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1432 {'loss': 12.993339538574219, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1433 {'loss': 4.978891372680664, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1434 {'loss': 0.7324799299240112, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1435 {'loss': 14.671473503112793, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1436 {'loss': 0.7791953086853027, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1437 {'loss': 2.0889077186584473, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1438 {'loss': 0.9822655916213989, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1439 {'loss': 9.133254051208496, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1440 {'loss': 1.000875473022461, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1441 {'loss': 0.7787774801254272, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1442 {'loss': 1.1041375398635864, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1443 {'loss': 1.1637656688690186, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1444 {'loss': 1.0328775644302368, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1445 {'loss': 8.156982421875, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1446 {'loss': 1.0720947980880737, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1447 {'loss': 0.8083151578903198, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1448 {'loss': 4.688918113708496, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1449 {'loss': 4.508963108062744, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1450 {'loss': 0.36011746525764465, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1451 {'loss': 0.9236279129981995, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1452 {'loss': 6.849339485168457, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1453 {'loss': 4.320389270782471, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1454 {'loss': 1.390760898590088, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1455 {'loss': 0.9977501034736633, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1456 {'loss': 0.8383066058158875, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1457 {'loss': 8.451272010803223, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1458 {'loss': 15.28860092163086, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1459 {'loss': 0.23737624287605286, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1460 {'loss': 15.358006477355957, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1461 {'loss': 7.147700309753418, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1462 {'loss': 1.0616984367370605, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1463 {'loss': 1.2439557313919067, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1464 {'loss': 0.9304187893867493, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1465 {'loss': 6.484945774078369, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1466 {'loss': 6.255388259887695, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1467 {'loss': 1.4995460510253906, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1468 {'loss': 14.65582275390625, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1469 {'loss': 1.4677658081054688, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1470 {'loss': 1.1929551362991333, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1471 {'loss': 3.465817928314209, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1472 {'loss': 3.9661850929260254, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1473 {'loss': 1.4025962352752686, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1474 {'loss': 0.9291164875030518, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1475 {'loss': 10.711901664733887, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1476 {'loss': 1.3527376651763916, 'reward': 0.29571428571428576, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1477 {'loss': 5.598031044006348, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1478 {'loss': 13.239506721496582, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1479 {'loss': 8.479498863220215, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1480 {'loss': 0.442909300327301, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1481 {'loss': 5.535645484924316, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1482 {'loss': 2.1253929138183594, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1483 {'loss': 1.3146946430206299, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1484 {'loss': 6.3252787590026855, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1485 {'loss': 1.3111965656280518, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1486 {'loss': 1.3143517971038818, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1487 {'loss': 0.9821559190750122, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1488 {'loss': 2.568199872970581, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1489 {'loss': 7.516385555267334, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1490 {'loss': 0.7064847946166992, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1491 {'loss': 10.503952980041504, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1492 {'loss': 1.3092979192733765, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1493 {'loss': 3.247842311859131, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1494 {'loss': 8.113987922668457, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1495 {'loss': 2.8410439491271973, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1496 {'loss': 11.459267616271973, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1497 {'loss': 7.234540939331055, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1498 {'loss': 0.7477901577949524, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1499 {'loss': 8.234735488891602, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1500 {'loss': 1.3673079013824463, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode 1500: Mean Reward (last 100 episodes) = 0.0051 ---\n",
      "Episode 1500: reward=0.0000, length=4\n",
      "  Latest sampled rule: grandparent(X6, X8) :- parent(X2, X6), parent(X5, X5), parent(X6, X8), parent(X8, X6).\n",
      "1501 {'loss': 1.2839298248291016, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1502 {'loss': 8.736966133117676, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1503 {'loss': 10.820976257324219, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1504 {'loss': 6.895371913909912, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1505 {'loss': 1.5830068588256836, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1506 {'loss': 13.664734840393066, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1507 {'loss': 13.812446594238281, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1508 {'loss': 1.6026833057403564, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1509 {'loss': 8.256515502929688, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1510 {'loss': 0.9945942759513855, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1511 {'loss': 1.5120197534561157, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1512 {'loss': 13.06187915802002, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1513 {'loss': 1.8434776067733765, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1514 {'loss': 0.9054420590400696, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1515 {'loss': 10.282181739807129, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1516 {'loss': 1.5960807800292969, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1517 {'loss': 10.798543930053711, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1518 {'loss': 5.250917434692383, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1519 {'loss': 5.311458587646484, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1520 {'loss': 1.3542715311050415, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1521 {'loss': 1.3088321685791016, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1522 {'loss': 7.1090989112854, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1523 {'loss': 4.284045696258545, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1524 {'loss': 16.7596378326416, 'reward': 1.01, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1525 {'loss': 4.3324713706970215, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1526 {'loss': 1.4877866506576538, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1527 {'loss': 1.43471097946167, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1528 {'loss': 1.3678395748138428, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1529 {'loss': 12.652393341064453, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1530 {'loss': 7.87564754486084, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1531 {'loss': 4.042325973510742, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1532 {'loss': 3.3919222354888916, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1533 {'loss': 1.7020349502563477, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1534 {'loss': 1.4355579614639282, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1535 {'loss': 4.766147613525391, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1536 {'loss': 6.3777031898498535, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1537 {'loss': 8.400634765625, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1538 {'loss': 2.7853879928588867, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1539 {'loss': 2.364062547683716, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1540 {'loss': 0.9340319037437439, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1541 {'loss': 3.6127429008483887, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1542 {'loss': 13.259044647216797, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1543 {'loss': 1.6504456996917725, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1544 {'loss': 5.591919422149658, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1545 {'loss': 6.350415229797363, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1546 {'loss': 11.85192584991455, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1547 {'loss': 7.407456874847412, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1548 {'loss': 9.864917755126953, 'reward': 0.743939393939394, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1549 {'loss': 1.2097176313400269, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1550 {'loss': 2.3796019554138184, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1551 {'loss': 1.418176293373108, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1552 {'loss': 8.878500938415527, 'reward': 0.41250000000000003, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1553 {'loss': 11.451796531677246, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1554 {'loss': 1.3139674663543701, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1555 {'loss': 2.2965707778930664, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1556 {'loss': 1.9853098392486572, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1557 {'loss': 2.9140634536743164, 'reward': 0.49888888888888894, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1558 {'loss': 2.73158860206604, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1559 {'loss': 1.213966727256775, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1560 {'loss': 6.607495307922363, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1561 {'loss': 2.0986599922180176, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1562 {'loss': 6.306049346923828, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1563 {'loss': 5.5838942527771, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1564 {'loss': 11.487836837768555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1565 {'loss': 12.675224304199219, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1566 {'loss': 11.064257621765137, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1567 {'loss': 5.254553318023682, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1568 {'loss': 9.041202545166016, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1569 {'loss': 1.1159988641738892, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1570 {'loss': 1.4884963035583496, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1571 {'loss': 11.679573059082031, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1572 {'loss': 11.434210777282715, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1573 {'loss': 11.79883861541748, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1574 {'loss': 3.04217529296875, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1575 {'loss': 2.66998553276062, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1576 {'loss': 1.3110283613204956, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1577 {'loss': 2.6434803009033203, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1578 {'loss': 5.974545478820801, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1579 {'loss': 13.840458869934082, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1580 {'loss': 3.2064437866210938, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1581 {'loss': 13.03780746459961, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1582 {'loss': 3.8714170455932617, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1583 {'loss': 2.7221298217773438, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1584 {'loss': 1.9771411418914795, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1585 {'loss': 11.892395973205566, 'reward': 0.7397727272727272, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1586 {'loss': 3.685269832611084, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1587 {'loss': 9.503799438476562, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1588 {'loss': 1.4020780324935913, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1589 {'loss': 1.8066091537475586, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1590 {'loss': 1.3787020444869995, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1591 {'loss': 1.9706367254257202, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1592 {'loss': 3.8907148838043213, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1593 {'loss': 11.981813430786133, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1594 {'loss': 0.8342084884643555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1595 {'loss': 2.268782138824463, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1596 {'loss': 6.872351169586182, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1597 {'loss': 13.660140991210938, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1598 {'loss': 1.5358994007110596, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1599 {'loss': 3.1164705753326416, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1600 {'loss': 1.7687987089157104, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode 1600: Mean Reward (last 100 episodes) = 0.0341 ---\n",
      "Episode 1600: reward=0.0000, length=4\n",
      "  Latest sampled rule: grandparent(X8, X1) :- parent(X2, X6), parent(X2, X6), parent(X6, X2), parent(X8, X6).\n",
      "1601 {'loss': 2.057326555252075, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1602 {'loss': 9.191300392150879, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1603 {'loss': 9.283028602600098, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1604 {'loss': 1.5206298828125, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1605 {'loss': 1.7005529403686523, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1606 {'loss': 1.9158947467803955, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1607 {'loss': 1.2051928043365479, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1608 {'loss': 13.234977722167969, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1609 {'loss': 7.540397644042969, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1610 {'loss': 4.829293727874756, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1611 {'loss': 7.989537239074707, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1612 {'loss': 1.4253182411193848, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1613 {'loss': 8.944231033325195, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1614 {'loss': 1.868675947189331, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1615 {'loss': 2.7279200553894043, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1616 {'loss': 1.337843418121338, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1617 {'loss': 1.1652722358703613, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1618 {'loss': 3.622849225997925, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1619 {'loss': 1.3086919784545898, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1620 {'loss': 3.0966477394104004, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1621 {'loss': 8.112630844116211, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1622 {'loss': 3.9512264728546143, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1623 {'loss': 10.53059196472168, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1624 {'loss': 1.0619194507598877, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1625 {'loss': 1.5904030799865723, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1626 {'loss': 11.524511337280273, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1627 {'loss': 9.454113006591797, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1628 {'loss': 4.2204909324646, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1629 {'loss': 3.3007640838623047, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1630 {'loss': 1.0354442596435547, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1631 {'loss': 1.2274258136749268, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1632 {'loss': 9.80810832977295, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1633 {'loss': 0.963786244392395, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1634 {'loss': 1.0353680849075317, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1635 {'loss': 0.8306474685668945, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1636 {'loss': 1.019742488861084, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1637 {'loss': 2.524686098098755, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1638 {'loss': 1.438475489616394, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1639 {'loss': 0.9892494082450867, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1640 {'loss': 1.2710148096084595, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1641 {'loss': 0.9983291625976562, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1642 {'loss': 9.109081268310547, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1643 {'loss': 1.6649043560028076, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1644 {'loss': 0.735957682132721, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1645 {'loss': 3.7084362506866455, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1646 {'loss': 1.1582380533218384, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1647 {'loss': 8.298089981079102, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1648 {'loss': 1.5737183094024658, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1649 {'loss': 12.782048225402832, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1650 {'loss': 8.615504264831543, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1651 {'loss': 15.352827072143555, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1652 {'loss': 3.193516254425049, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1653 {'loss': 1.2200826406478882, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1654 {'loss': 0.9041404724121094, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1655 {'loss': 1.100486397743225, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1656 {'loss': 1.3338199853897095, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1657 {'loss': 3.159494638442993, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1658 {'loss': 13.284332275390625, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1659 {'loss': 2.4329264163970947, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1660 {'loss': 0.7519305348396301, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1661 {'loss': 1.0033422708511353, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1662 {'loss': 5.783421516418457, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1663 {'loss': 4.546391487121582, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1664 {'loss': 13.345222473144531, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1665 {'loss': 0.7260031700134277, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1666 {'loss': 12.702293395996094, 'reward': 0.3372727272727273, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1667 {'loss': 9.717103958129883, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1668 {'loss': 3.125455141067505, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1669 {'loss': 11.231148719787598, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1670 {'loss': 6.829872131347656, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1671 {'loss': 1.0841033458709717, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1672 {'loss': 7.084454536437988, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1673 {'loss': 1.3264281749725342, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1674 {'loss': 1.7167952060699463, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1675 {'loss': 0.7457228302955627, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1676 {'loss': 7.691694259643555, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1677 {'loss': 12.84084415435791, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1678 {'loss': 3.5540642738342285, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1679 {'loss': 1.6591194868087769, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1680 {'loss': 3.7973713874816895, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1681 {'loss': 7.624520301818848, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1682 {'loss': 13.891424179077148, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1683 {'loss': 1.4434691667556763, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1684 {'loss': 4.175962924957275, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1685 {'loss': 9.739192962646484, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1686 {'loss': 9.809818267822266, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1687 {'loss': 0.9562947154045105, 'reward': 0.3372727272727273, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1688 {'loss': 1.2321847677230835, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1689 {'loss': 6.355406761169434, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1690 {'loss': 12.087911605834961, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1691 {'loss': 5.741530895233154, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1692 {'loss': 0.35858315229415894, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1693 {'loss': 1.4822455644607544, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1694 {'loss': 7.506411075592041, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1695 {'loss': 5.970947742462158, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1696 {'loss': 5.240779876708984, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1697 {'loss': 0.6512743234634399, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1698 {'loss': 5.506328582763672, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1699 {'loss': 10.0568265914917, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1700 {'loss': 9.434831619262695, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "\n",
      "--- Episode 1700: Mean Reward (last 100 episodes) = 0.0067 ---\n",
      "Episode 1700: reward=0.0000, length=10\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X2, X3), parent(X0, X2).\n",
      "1701 {'loss': 6.788535118103027, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1702 {'loss': 0.7164152264595032, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1703 {'loss': 6.831876277923584, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1704 {'loss': 4.043301105499268, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1705 {'loss': 9.918142318725586, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1706 {'loss': 1.0275373458862305, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1707 {'loss': 1.2602932453155518, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1708 {'loss': 9.25888442993164, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1709 {'loss': 3.976527214050293, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1710 {'loss': 1.6157262325286865, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1711 {'loss': 7.214631080627441, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1712 {'loss': 1.0605591535568237, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1713 {'loss': 6.067317485809326, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1714 {'loss': 10.524558067321777, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1715 {'loss': 10.09187126159668, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1716 {'loss': 1.2394177913665771, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1717 {'loss': 1.4651051759719849, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1718 {'loss': 2.989048957824707, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1719 {'loss': 1.1949570178985596, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1720 {'loss': 1.450334906578064, 'reward': 0.29571428571428576, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1721 {'loss': 1.155547022819519, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1722 {'loss': 0.7785005569458008, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1723 {'loss': 3.0048818588256836, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1724 {'loss': 1.1092021465301514, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1725 {'loss': 7.215651512145996, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1726 {'loss': 0.6175016164779663, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1727 {'loss': 1.1559524536132812, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1728 {'loss': 1.8262773752212524, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1729 {'loss': 8.271734237670898, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1730 {'loss': 7.183710098266602, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1731 {'loss': 1.9570434093475342, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1732 {'loss': 10.04930305480957, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1733 {'loss': 3.153757095336914, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1734 {'loss': 5.988665580749512, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1735 {'loss': 1.0143870115280151, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1736 {'loss': 3.170314073562622, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1737 {'loss': 0.7483134269714355, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1738 {'loss': 1.0470613241195679, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1739 {'loss': 1.2875031232833862, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1740 {'loss': 2.825845241546631, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1741 {'loss': 9.517281532287598, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1742 {'loss': 9.991547584533691, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1743 {'loss': 0.7287790775299072, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1744 {'loss': 8.576909065246582, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1745 {'loss': 0.9654155969619751, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1746 {'loss': 10.556236267089844, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1747 {'loss': 0.9548829793930054, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1748 {'loss': 0.9679257273674011, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1749 {'loss': 5.897830486297607, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1750 {'loss': 4.386305809020996, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1751 {'loss': 2.95839786529541, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1752 {'loss': 1.2568004131317139, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1753 {'loss': 1.179339051246643, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1754 {'loss': 1.2755765914916992, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1755 {'loss': 3.040318727493286, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1756 {'loss': 11.698593139648438, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1757 {'loss': 4.430627346038818, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1758 {'loss': 22.302871704101562, 'reward': 0.743939393939394, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1759 {'loss': 14.770645141601562, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1760 {'loss': 1.1782339811325073, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1761 {'loss': 11.818800926208496, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1762 {'loss': 11.995545387268066, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1763 {'loss': 7.885296821594238, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1764 {'loss': 0.6365180611610413, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1765 {'loss': 3.8259010314941406, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1766 {'loss': 1.668954849243164, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1767 {'loss': 5.927301406860352, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1768 {'loss': 5.380081653594971, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1769 {'loss': 0.4783340394496918, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1770 {'loss': 7.0192766189575195, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1771 {'loss': 9.457834243774414, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1772 {'loss': 3.73414945602417, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1773 {'loss': 0.8127291798591614, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1774 {'loss': 1.2842686176300049, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1775 {'loss': 9.681425094604492, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1776 {'loss': 1.1475764513015747, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1777 {'loss': 7.221981525421143, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1778 {'loss': 1.33266282081604, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1779 {'loss': 1.5871622562408447, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1780 {'loss': 10.166177749633789, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1781 {'loss': 10.405929565429688, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1782 {'loss': 11.68520736694336, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1783 {'loss': 7.0025129318237305, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1784 {'loss': 1.4716013669967651, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1785 {'loss': 1.2586244344711304, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1786 {'loss': 1.0421240329742432, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1787 {'loss': 8.69135856628418, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1788 {'loss': 1.4480022192001343, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1789 {'loss': 1.4848642349243164, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1790 {'loss': 6.833727836608887, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1791 {'loss': 11.417989730834961, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1792 {'loss': 8.683902740478516, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1793 {'loss': 1.2756073474884033, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1794 {'loss': 8.993236541748047, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1795 {'loss': 1.8938449621200562, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1796 {'loss': 1.5422440767288208, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1797 {'loss': 13.510333061218262, 'reward': 0.1372727272727272, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1798 {'loss': 2.6303112506866455, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1799 {'loss': 5.132437229156494, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1800 {'loss': 1.6119818687438965, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode 1800: Mean Reward (last 100 episodes) = 0.0118 ---\n",
      "Episode 1800: reward=0.0000, length=8\n",
      "  Latest sampled rule: grandparent(X0, X0) :- parent(X2, X2), parent(X5, X5), parent(X6, X6), parent(X6, X5).\n",
      "1801 {'loss': 1.3006186485290527, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1802 {'loss': 5.217839241027832, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1803 {'loss': 2.863586664199829, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1804 {'loss': 12.907747268676758, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1805 {'loss': 2.015221118927002, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1806 {'loss': 10.2047119140625, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1807 {'loss': 12.693548202514648, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1808 {'loss': 1.3754456043243408, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1809 {'loss': 1.2217284440994263, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1810 {'loss': 11.668115615844727, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1811 {'loss': 6.64300012588501, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1812 {'loss': 4.625921726226807, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1813 {'loss': 1.1851261854171753, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1814 {'loss': 4.318481922149658, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1815 {'loss': 0.8404785394668579, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1816 {'loss': 5.319582939147949, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1817 {'loss': 7.202446937561035, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1818 {'loss': 1.230250597000122, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1819 {'loss': 1.3889796733856201, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1820 {'loss': 3.634899616241455, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1821 {'loss': 4.1446685791015625, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1822 {'loss': 1.4681516885757446, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1823 {'loss': 1.2316631078720093, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1824 {'loss': 5.98945951461792, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1825 {'loss': 4.023285388946533, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1826 {'loss': 0.8717544674873352, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1827 {'loss': 12.404830932617188, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1828 {'loss': 1.445033311843872, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1829 {'loss': 12.006579399108887, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1830 {'loss': 5.006423473358154, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1831 {'loss': 5.923434257507324, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1832 {'loss': 1.4635363817214966, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1833 {'loss': 10.458808898925781, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1834 {'loss': 9.433257102966309, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1835 {'loss': 10.897321701049805, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1836 {'loss': 2.994352340698242, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1837 {'loss': 10.056150436401367, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1838 {'loss': 1.2359812259674072, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1839 {'loss': 1.3909403085708618, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1840 {'loss': 3.884613513946533, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1841 {'loss': 8.45298957824707, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1842 {'loss': 11.05330753326416, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1843 {'loss': 8.805333137512207, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1844 {'loss': 7.13337516784668, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1845 {'loss': 1.4676814079284668, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1846 {'loss': 6.127525806427002, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1847 {'loss': 1.1812834739685059, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1848 {'loss': 1.3541557788848877, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1849 {'loss': 6.4985504150390625, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1850 {'loss': 9.046358108520508, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1851 {'loss': 8.070953369140625, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1852 {'loss': 4.658279895782471, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1853 {'loss': 1.4723968505859375, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1854 {'loss': 3.484090566635132, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1855 {'loss': 1.2817412614822388, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1856 {'loss': 5.048994064331055, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1857 {'loss': 11.507089614868164, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1858 {'loss': 8.441911697387695, 'reward': 0.743939393939394, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1859 {'loss': 1.2386391162872314, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1860 {'loss': 11.181437492370605, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1861 {'loss': 5.161961555480957, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1862 {'loss': 6.8591837882995605, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1863 {'loss': 5.413360595703125, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1864 {'loss': 4.894287586212158, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1865 {'loss': 8.431227684020996, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1866 {'loss': 2.4617974758148193, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1867 {'loss': 9.40406608581543, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1868 {'loss': 4.725477695465088, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1869 {'loss': 3.9422008991241455, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1870 {'loss': 5.733126163482666, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1871 {'loss': 6.693897724151611, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1872 {'loss': 3.102386951446533, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1873 {'loss': 3.503185272216797, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1874 {'loss': 1.9953011274337769, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1875 {'loss': 8.741093635559082, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1876 {'loss': 1.2794972658157349, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1877 {'loss': 9.195034980773926, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1878 {'loss': 8.542448043823242, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1879 {'loss': 1.3555920124053955, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1880 {'loss': 4.984840393066406, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1881 {'loss': 3.700072765350342, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1882 {'loss': 10.165078163146973, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1883 {'loss': 5.757803440093994, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1884 {'loss': 9.941417694091797, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1885 {'loss': 8.5382661819458, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1886 {'loss': 8.761438369750977, 'reward': 0.743939393939394, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1887 {'loss': 1.388059377670288, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1888 {'loss': 4.2489399909973145, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1889 {'loss': 10.470730781555176, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1890 {'loss': 7.438815116882324, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1891 {'loss': 1.6193066835403442, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1892 {'loss': 1.3033301830291748, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1893 {'loss': 5.70762300491333, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1894 {'loss': 0.8234665989875793, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1895 {'loss': 4.606057167053223, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1896 {'loss': 5.608386993408203, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1897 {'loss': 5.477811813354492, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1898 {'loss': 6.400335311889648, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1899 {'loss': 3.432715892791748, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1900 {'loss': 1.3363068103790283, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode 1900: Mean Reward (last 100 episodes) = 0.0149 ---\n",
      "Episode 1900: reward=0.0000, length=8\n",
      "  Latest sampled rule: grandparent(X8, X8) :- parent(X2, X8), parent(X4, X6), parent(X6, X2), parent(X8, X9).\n",
      "1901 {'loss': 1.0980544090270996, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1902 {'loss': 2.935201644897461, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1903 {'loss': 7.345108509063721, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1904 {'loss': 5.850412368774414, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1905 {'loss': 10.644585609436035, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1906 {'loss': 12.757118225097656, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1907 {'loss': 4.8970513343811035, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1908 {'loss': 4.904101848602295, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1909 {'loss': 1.7877724170684814, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1910 {'loss': 7.729378700256348, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1911 {'loss': 9.386665344238281, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1912 {'loss': 6.316206932067871, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "1913 {'loss': 8.893712997436523, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1914 {'loss': 10.871183395385742, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1915 {'loss': 5.343184471130371, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1916 {'loss': 1.7829618453979492, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1917 {'loss': 0.6756882667541504, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1918 {'loss': 12.003448486328125, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1919 {'loss': 5.762994766235352, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1920 {'loss': 1.0541857481002808, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1921 {'loss': 7.041569709777832, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1922 {'loss': 1.3799468278884888, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1923 {'loss': 9.64063549041748, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1924 {'loss': 11.22962760925293, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1925 {'loss': 8.186063766479492, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1926 {'loss': 1.1602983474731445, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1927 {'loss': 1.017223596572876, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1928 {'loss': 1.6003960371017456, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1929 {'loss': 9.788256645202637, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1930 {'loss': 5.297617435455322, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1931 {'loss': 10.849512100219727, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1932 {'loss': 5.41070556640625, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1933 {'loss': 9.818300247192383, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1934 {'loss': 1.947522759437561, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1935 {'loss': 5.481668949127197, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1936 {'loss': 10.61884880065918, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1937 {'loss': 5.314750671386719, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1938 {'loss': 1.6812230348587036, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1939 {'loss': 1.3084932565689087, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1940 {'loss': 2.6299855709075928, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1941 {'loss': 6.184323787689209, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1942 {'loss': 1.484603762626648, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1943 {'loss': 1.2914490699768066, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1944 {'loss': 1.207875370979309, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1945 {'loss': 1.9241777658462524, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1946 {'loss': 1.4497697353363037, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1947 {'loss': 1.1542062759399414, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1948 {'loss': 10.835688591003418, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1949 {'loss': 4.67475700378418, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1950 {'loss': 1.1159534454345703, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1951 {'loss': 1.8435271978378296, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "1952 {'loss': 10.32122802734375, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1953 {'loss': 1.1047492027282715, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1954 {'loss': 10.642675399780273, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1955 {'loss': 0.9912922978401184, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1956 {'loss': 1.1115812063217163, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1957 {'loss': 2.8738865852355957, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "1958 {'loss': 0.9750112295150757, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1959 {'loss': 1.1288810968399048, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "1960 {'loss': 0.9790158271789551, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1961 {'loss': 0.9746471643447876, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "1962 {'loss': 13.806589126586914, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1963 {'loss': 9.390359878540039, 'reward': 0.3397727272727272, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1964 {'loss': 3.477313995361328, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1965 {'loss': 7.858645439147949, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1966 {'loss': 0.8916233777999878, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1967 {'loss': 1.3001139163970947, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1968 {'loss': 0.9706717133522034, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1969 {'loss': 10.397062301635742, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1970 {'loss': 7.1831464767456055, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1971 {'loss': 9.969246864318848, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1972 {'loss': 3.6030163764953613, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1973 {'loss': 11.308040618896484, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1974 {'loss': 6.022404193878174, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1975 {'loss': 0.7828291654586792, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1976 {'loss': 1.0231585502624512, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1977 {'loss': 5.601289749145508, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1978 {'loss': 9.62318229675293, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1979 {'loss': 1.0531805753707886, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1980 {'loss': 1.3516889810562134, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': False}\n",
      "1981 {'loss': 9.092150688171387, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1982 {'loss': 12.603307723999023, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1983 {'loss': 11.075226783752441, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "1984 {'loss': 10.397607803344727, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1985 {'loss': 9.58142375946045, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1986 {'loss': 6.4565815925598145, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1987 {'loss': 9.667558670043945, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1988 {'loss': 10.799993515014648, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "1989 {'loss': 5.2181291580200195, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1990 {'loss': 1.152043342590332, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "1991 {'loss': 1.2834397554397583, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1992 {'loss': 5.348110675811768, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1993 {'loss': 9.733402252197266, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1994 {'loss': 8.930930137634277, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "1995 {'loss': 3.829515218734741, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "1996 {'loss': 1.592349648475647, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "1997 {'loss': 5.454423904418945, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "1998 {'loss': 2.4125921726226807, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n",
      "1999 {'loss': 1.8690084218978882, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "2000 {'loss': 1.6817492246627808, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "\n",
      "--- Episode 2000: Mean Reward (last 100 episodes) = 0.0034 ---\n",
      "Episode 2000: reward=0.0000, length=4\n",
      "  Latest sampled rule: grandparent(X2, X2) :- parent(X2, X5), parent(X4, X5), parent(X6, X7), parent(X6, X9).\n",
      "2001 {'loss': 3.48439359664917, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "2002 {'loss': 1.880597472190857, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "2003 {'loss': 8.621542930603027, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "2004 {'loss': 7.870945453643799, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "2005 {'loss': 1.4439425468444824, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "2006 {'loss': 6.029879570007324, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7397727272727272}\n",
      "2007 {'loss': 5.0823469161987305, 'reward': 0.21666666666666667, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "2008 {'loss': 6.953193664550781, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "2009 {'loss': 2.025730848312378, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "2010 {'loss': 7.14060640335083, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "2011 {'loss': 11.266471862792969, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "2012 {'loss': 1.5800914764404297, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "2013 {'loss': 1.3792641162872314, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "2014 {'loss': 1.37699556350708, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "2015 {'loss': 14.52847671508789, 'reward': 0.1372727272727272, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "2016 {'loss': 14.498376846313477, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "2017 {'loss': 1.3064109086990356, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "2018 {'loss': 6.528141975402832, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "2019 {'loss': 4.269935131072998, 'reward': 1e-06, 'trajectory_length': 6, 'log_Z': 0.0, 'replay_used': False}\n",
      "2020 {'loss': 1.4804103374481201, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "2021 {'loss': 4.983098983764648, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "2022 {'loss': 1.1957635879516602, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "2023 {'loss': 0.9283002614974976, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "2024 {'loss': 7.762060165405273, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.898888888888889}\n",
      "2025 {'loss': 1.228299617767334, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "2026 {'loss': 5.211440086364746, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "2027 {'loss': 6.330081939697266, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "2028 {'loss': 9.774794578552246, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.01}\n",
      "2029 {'loss': 1.0106786489486694, 'reward': 1e-06, 'trajectory_length': 9, 'log_Z': 0.0, 'replay_used': False}\n",
      "2030 {'loss': 1.0011323690414429, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "2031 {'loss': 9.696467399597168, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "2032 {'loss': 3.637019395828247, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.61}\n",
      "2033 {'loss': 1.929234266281128, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "2034 {'loss': 5.110409736633301, 'reward': 1e-06, 'trajectory_length': 5, 'log_Z': 0.0, 'replay_used': False}\n",
      "2035 {'loss': 6.48948335647583, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "2036 {'loss': 13.699892044067383, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.743939393939394}\n",
      "2037 {'loss': 11.397512435913086, 'reward': 1e-06, 'trajectory_length': 7, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "2038 {'loss': 5.878213405609131, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 0.7372727272727273}\n",
      "2039 {'loss': 12.300456047058105, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': True, 'replay_reward': 1.0125}\n",
      "2040 {'loss': 3.037632942199707, 'reward': 1e-06, 'trajectory_length': 10, 'log_Z': 0.0, 'replay_used': False}\n",
      "2041 {'loss': 1.097825288772583, 'reward': 1e-06, 'trajectory_length': 4, 'log_Z': 0.0, 'replay_used': False}\n",
      "2042 {'loss': 1.0264145135879517, 'reward': 1e-06, 'trajectory_length': 8, 'log_Z': 0.0, 'replay_used': False}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m recent_rules = []  \u001b[38;5;66;03m# Track last 50 rules for analysis\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     metrics = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive_examples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnegative_examples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28mprint\u001b[39m(episode, metrics)\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GFLOWNET-ILP/src/training.py:678\u001b[39m, in \u001b[36mGFlowNetTrainer.train_step\u001b[39m\u001b[34m(self, initial_state, positive_examples, negative_examples)\u001b[39m\n\u001b[32m    676\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(total_loss, torch.Tensor) \u001b[38;5;129;01mand\u001b[39;00m total_loss.requires_grad:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     \u001b[43mtotal_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    679\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.step()\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# Step the exploration strategy (e.g., for parameter decay)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MarinaWeb/lib/python3.13/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MarinaWeb/lib/python3.13/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/MarinaWeb/lib/python3.13/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "num_episodes = config['num_episodes']\n",
    "initial_state = get_initial_state('grandparent', 2)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"TRAINING ({num_episodes} episodes)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rewards = []\n",
    "discovered_rules = {}  # Rule string -> (reward, episode, scores)\n",
    "recent_rules = []  # Track last 50 rules for analysis\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    metrics = trainer.train_step(initial_state, positive_examples, negative_examples)\n",
    "\n",
    "    print(episode, metrics)\n",
    "    if metrics:\n",
    "        rewards.append(metrics['reward'])\n",
    "\n",
    "        # Record metrics with visualizer\n",
    "        visualizer.record_episode(episode, metrics)\n",
    "\n",
    "        # Sample trajectories periodically to see what rules are being found\n",
    "        if episode % 10 == 0:\n",
    "            trajectory, reward = trainer.generate_trajectory(\n",
    "                initial_state, positive_examples, negative_examples\n",
    "            )\n",
    "            theory = trajectory[-1].next_state if trajectory else initial_state\n",
    "            rule_str = theory_to_string(theory)\n",
    "\n",
    "            scores = reward_calc.get_detailed_scores(theory, positive_examples, negative_examples)\n",
    "\n",
    "            # Record with visualizer\n",
    "            visualizer.record_rule(rule_str, reward, episode, scores)\n",
    "\n",
    "            # Add detailed metrics to visualizer\n",
    "            visualizer.record_episode(episode, {\n",
    "                **metrics,\n",
    "                'precision': scores['precision'],\n",
    "                'recall': scores['recall'],\n",
    "                'f1_score': scores['f1_score'],\n",
    "                'accuracy': scores['accuracy']\n",
    "            })\n",
    "\n",
    "            discovered_rules[rule_str] = (reward, episode, scores)\n",
    "\n",
    "            recent_rules.append((rule_str, reward, episode, scores))\n",
    "            if len(recent_rules) > 100:\n",
    "                recent_rules.pop(0)\n",
    "\n",
    "        if episode % 100 == 0 and recent_rules:\n",
    "            mean_reward = np.mean(rewards[-100:])\n",
    "            print(f\"\\n--- Episode {episode:4d}: Mean Reward (last 100 episodes) = {mean_reward:.4f} ---\")\n",
    "            latest_rule, latest_reward, _, _ = recent_rules[-1]\n",
    "            print(f\"Episode {episode:4d}: reward={metrics['reward']:.4f}, length={metrics['trajectory_length']}\")\n",
    "            print(f\"  Latest sampled rule: {latest_rule}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c981f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRAINING RESULTS\n",
      "================================================================================\n",
      "\n",
      "Final avg reward (last 100): 0.0000\n",
      "Max reward: 1.0167\n",
      "High-reward episodes (>0.8): 4\n",
      "Unique rules discovered: 384\n",
      "\n",
      "================================================================================\n",
      "TOP DISCOVERED RULES\n",
      "================================================================================\n",
      "\n",
      "Showing top 10 rules by reward:\n",
      "\n",
      "1. [Reward: 0.8989] grandparent(X2, X1) :- parent(X2, X4), parent(X4, X5), parent(X6, X4), parent(X8, X1).\n",
      "   Discovered at Episode: 1340\n",
      "   Confusion Matrix: TP=4, FN=0, FP=1, TN=4\n",
      "   Coverage: 4/4 positives, 1/5 negatives\n",
      "   Metrics: Precision=0.8000, Recall=1.0000, F1=0.8889\n",
      "   Penalties: Disconnected=0 (-0.00), Self-loops=0 (-0.00), Free-vars=0 (-0.00)\n",
      "\n",
      "2. [Reward: 0.6100] grandparent(X6, X1) :- parent(X2, X1), parent(X4, X2), parent(X6, X7), parent(X8, X9).\n",
      "   Discovered at Episode: 410\n",
      "   Confusion Matrix: TP=4, FN=0, FP=0, TN=5\n",
      "   Coverage: 4/4 positives, 0/5 negatives\n",
      "   Metrics: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "   Penalties: Disconnected=2 (-0.40), Self-loops=0 (-0.00), Free-vars=0 (-0.00)\n",
      "\n",
      "3. [Reward: 0.2957] grandparent(X5, X1) :- parent(X5, X3), parent(X4, X5), parent(X6, X5), parent(X8, X1).\n",
      "   Discovered at Episode: 650\n",
      "   Confusion Matrix: TP=1, FN=3, FP=2, TN=3\n",
      "   Coverage: 1/4 positives, 2/5 negatives\n",
      "   Metrics: Precision=0.3333, Recall=0.2500, F1=0.2857\n",
      "   Penalties: Disconnected=0 (-0.00), Self-loops=0 (-0.00), Free-vars=0 (-0.00)\n",
      "\n",
      "4. [Reward: 0.2957] grandparent(X2, X1) :- parent(X2, X3), parent(X4, X2), parent(X6, X1), parent(X6, X9).\n",
      "   Discovered at Episode: 1880\n",
      "   Confusion Matrix: TP=1, FN=3, FP=2, TN=3\n",
      "   Coverage: 1/4 positives, 2/5 negatives\n",
      "   Metrics: Precision=0.3333, Recall=0.2500, F1=0.2857\n",
      "   Penalties: Disconnected=0 (-0.00), Self-loops=0 (-0.00), Free-vars=0 (-0.00)\n",
      "\n",
      "5. [Reward: 0.1373] grandparent(X0, X1) :- parent(X0, X3), parent(X4, X5), parent(X6, X1), parent(X5, X9).\n",
      "   Discovered at Episode: 370\n",
      "   Confusion Matrix: TP=4, FN=0, FP=3, TN=2\n",
      "   Coverage: 4/4 positives, 3/5 negatives\n",
      "   Metrics: Precision=0.5714, Recall=1.0000, F1=0.7273\n",
      "   Penalties: Disconnected=3 (-0.60), Self-loops=0 (-0.00), Free-vars=0 (-0.00)\n",
      "\n",
      "6. [Reward: 0.0000] grandparent(X6, X2) :- parent(X2, X3), parent(X4, X5), parent(X6, X7).\n",
      "   Discovered at Episode: 140\n",
      "   Confusion Matrix: TP=1, FN=3, FP=5, TN=0\n",
      "   Coverage: 1/4 positives, 5/5 negatives\n",
      "   Metrics: Precision=0.1667, Recall=0.2500, F1=0.2000\n",
      "   Penalties: Disconnected=2 (-0.40), Self-loops=0 (-0.00), Free-vars=0 (-0.00)\n",
      "\n",
      "7. [Reward: 0.0000] grandparent(X4, X1) :- parent(X2, X3), parent(X4, X5), parent(X6, X1), parent(X8, X4).\n",
      "   Discovered at Episode: 1560\n",
      "   Confusion Matrix: TP=1, FN=3, FP=2, TN=3\n",
      "   Coverage: 1/4 positives, 2/5 negatives\n",
      "   Metrics: Precision=0.3333, Recall=0.2500, F1=0.2857\n",
      "   Penalties: Disconnected=2 (-0.40), Self-loops=0 (-0.00), Free-vars=0 (-0.00)\n",
      "\n",
      "8. [Reward: 0.0000] grandparent(X0, X2) :- parent(X2, X0), parent(X2, X2), parent(X6, X7), parent(X8, X7).\n",
      "   Discovered at Episode: 0\n",
      "   Confusion Matrix: TP=0, FN=4, FP=0, TN=5\n",
      "   Coverage: 0/4 positives, 0/5 negatives\n",
      "   Metrics: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   Penalties: Disconnected=3 (-0.60), Self-loops=1 (-0.30), Free-vars=0 (-0.00)\n",
      "\n",
      "9. [Reward: 0.0000] grandparent(X6, X8) :- parent(X6, X6), parent(X6, X5), parent(X6, X7), parent(X8, X6).\n",
      "   Discovered at Episode: 10\n",
      "   Confusion Matrix: TP=0, FN=4, FP=0, TN=5\n",
      "   Coverage: 0/4 positives, 0/5 negatives\n",
      "   Metrics: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   Penalties: Disconnected=0 (-0.00), Self-loops=1 (-0.30), Free-vars=0 (-0.00)\n",
      "\n",
      "10. [Reward: 0.0000] grandparent(X1, X1) :- parent(X2, X1), parent(X4, X6), parent(X6, X1).\n",
      "   Discovered at Episode: 20\n",
      "   Confusion Matrix: TP=0, FN=4, FP=0, TN=5\n",
      "   Coverage: 0/4 positives, 0/5 negatives\n",
      "   Metrics: Precision=0.0000, Recall=0.0000, F1=0.0000\n",
      "   Penalties: Disconnected=0 (-0.00), Self-loops=1 (-0.30), Free-vars=0 (-0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if rewards:\n",
    "    final_avg_reward = np.mean(rewards[-100:]) if len(rewards) > 100 else np.mean(rewards)\n",
    "    max_reward = np.max(rewards)\n",
    "    high_reward_count = sum(1 for r in rewards if r > 0.8)\n",
    "\n",
    "    print(f\"\\nFinal avg reward (last 100): {final_avg_reward:.4f}\")\n",
    "    print(f\"Max reward: {max_reward:.4f}\")\n",
    "    print(f\"High-reward episodes (>0.8): {high_reward_count}\")\n",
    "else:\n",
    "    print(\"No training data was generated.\")\n",
    "\n",
    "print(f\"Unique rules discovered: {len(discovered_rules)}\")\n",
    "\n",
    "\n",
    "# Show discovered rules sorted by reward\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP DISCOVERED RULES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sorted_rules = sorted(discovered_rules.items(), key=lambda x: x[1][0], reverse=True)\n",
    "\n",
    "print(\"\\nShowing top 10 rules by reward:\\n\")\n",
    "\n",
    "for i, (rule_str, (reward, episode, scores)) in enumerate(sorted_rules[:10], 1):\n",
    "    pos_total = scores['TP'] + scores['FN']\n",
    "    neg_total = scores['FP'] + scores['TN']\n",
    "    print(f\"{i}. [Reward: {scores['reward']:.4f}] {rule_str}\")\n",
    "    print(f\"   Discovered at Episode: {episode}\")\n",
    "    print(f\"   Confusion Matrix: TP={scores['TP']}, FN={scores['FN']}, FP={scores['FP']}, TN={scores['TN']}\")\n",
    "    print(f\"   Coverage: {scores['TP']}/{pos_total} positives, \"\n",
    "          f\"{scores['FP']}/{neg_total} negatives\")\n",
    "    print(f\"   Metrics: Precision={scores['precision']:.4f}, Recall={scores['recall']:.4f}, F1={scores['f1_score']:.4f}\")\n",
    "    print(f\"   Penalties: Disconnected={scores['num_disconnected_vars']} (-{scores['disconnected_penalty']:.2f}), \"\n",
    "          f\"Self-loops={scores['num_self_loops']} (-{scores['self_loop_penalty']:.2f}), \"\n",
    "          f\"Free-vars={scores['num_free_vars']} (-{scores['free_var_penalty']:.2f})\")\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7bcf90e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REPLAY BUFFER ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Replay buffer size: 8\n",
      "\n",
      "Top 10 rules in replay buffer:\n",
      "\n",
      "1. [Reward: 1.0167] grandparent(X0, X1) :- parent(X2, X1), parent(X0, X2).\n",
      "   Coverage: 4/4 positives, 0/5 negatives\n",
      "   Issues: 0 disconnected, 0 self-loops, 0 free-vars\n",
      "\n",
      "2. [Reward: 1.0167] grandparent(X0, X5) :- parent(X0, X3), parent(X3, X5).\n",
      "   Coverage: 4/4 positives, 0/5 negatives\n",
      "   Issues: 0 disconnected, 0 self-loops, 0 free-vars\n",
      "\n",
      "3. [Reward: 1.0100] grandparent(X6, X5) :- parent(X2, X5), parent(X2, X5), parent(X6, X7), parent(X8, X2).\n",
      "   Coverage: 4/4 positives, 0/5 negatives\n",
      "   Issues: 0 disconnected, 0 self-loops, 0 free-vars\n",
      "\n",
      "4. [Reward: 0.8989] grandparent(X4, X1) :- parent(X2, X3), parent(X4, X2), parent(X6, X7), parent(X6, X1).\n",
      "   Coverage: 4/4 positives, 1/5 negatives\n",
      "   Issues: 0 disconnected, 0 self-loops, 0 free-vars\n",
      "\n",
      "5. [Reward: 0.7439] grandparent(X0, X5) :- parent(X0, X3), parent(X4, X5).\n",
      "   Coverage: 4/4 positives, 3/5 negatives\n",
      "   Issues: 0 disconnected, 0 self-loops, 0 free-vars\n",
      "\n",
      "6. [Reward: 0.7439] grandparent(X2, X5) :- parent(X2, X3), parent(X4, X5).\n",
      "   Coverage: 4/4 positives, 3/5 negatives\n",
      "   Issues: 0 disconnected, 0 self-loops, 0 free-vars\n",
      "\n",
      "7. [Reward: 0.6100] grandparent(X4, X1) :- parent(X6, X1), parent(X4, X6), parent(X6, X7), parent(X8, X9).\n",
      "   Coverage: 4/4 positives, 0/5 negatives\n",
      "   Issues: 2 disconnected, 0 self-loops, 0 free-vars\n",
      "\n",
      "8. [Reward: 0.6100] grandparent(X2, X1) :- parent(X2, X3), parent(X2, X6), parent(X6, X1), parent(X8, X9).\n",
      "   Coverage: 4/4 positives, 0/5 negatives\n",
      "   Issues: 2 disconnected, 0 self-loops, 0 free-vars\n",
      "\n",
      "================================================================================\n",
      "REPLAY BUFFER QUALITY STATISTICS\n",
      "================================================================================\n",
      "\n",
      "Perfect rules (100% recall, 0 false positives): 5/8 (62.5%)\n",
      "Rules with disconnected variables: 2/8 (25.0%)\n",
      "Rules with self-loops: 0/8 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze replay buffer\n",
    "print(\"=\"*80)\n",
    "print(\"REPLAY BUFFER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if trainer.replay_buffer and len(trainer.replay_buffer.buffer) > 0:\n",
    "    print(f\"\\nReplay buffer size: {len(trainer.replay_buffer.buffer)}\")\n",
    "\n",
    "    replay_rules = []\n",
    "    for trajectory, reward in trainer.replay_buffer.buffer:\n",
    "        theory = trajectory[-1].next_state\n",
    "        rule_str = theory_to_string(theory)\n",
    "        scores = reward_calc.get_detailed_scores(theory, positive_examples, negative_examples)\n",
    "        replay_rules.append((rule_str, reward, scores))\n",
    "\n",
    "    replay_rules.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(f\"\\nTop 10 rules in replay buffer:\\n\")\n",
    "\n",
    "    for i, (rule_str, reward, scores) in enumerate(replay_rules[:10], 1):\n",
    "        pos_total = scores['TP'] + scores['FN']\n",
    "        neg_total = scores['FP'] + scores['TN']\n",
    "        print(f\"{i}. [Reward: {reward:.4f}] {rule_str}\")\n",
    "        print(f\"   Coverage: {scores['TP']}/{pos_total} positives, \"\n",
    "              f\"{scores['FP']}/{neg_total} negatives\")\n",
    "        print(f\"   Issues: {scores['num_disconnected_vars']} disconnected, \"\n",
    "              f\"{scores['num_self_loops']} self-loops, \"\n",
    "              f\"{scores['num_free_vars']} free-vars\")\n",
    "        print()\n",
    "\n",
    "    # Quality statistics\n",
    "    num_perfect = sum(1 for _, _, s in replay_rules if s['recall'] == 1.0 and s['FP'] == 0)\n",
    "    num_disconnected = sum(1 for _, _, s in replay_rules if s['num_disconnected_vars'] > 0)\n",
    "    num_self_loops = sum(1 for _, _, s in replay_rules if s['num_self_loops'] > 0)\n",
    "    buffer_size = len(replay_rules)\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(\"REPLAY BUFFER QUALITY STATISTICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nPerfect rules (100% recall, 0 false positives): {num_perfect}/{buffer_size} ({100*num_perfect/buffer_size:.1f}%)\")\n",
    "    print(f\"Rules with disconnected variables: {num_disconnected}/{buffer_size} ({100*num_disconnected/buffer_size:.1f}%)\")\n",
    "    print(f\"Rules with self-loops: {num_self_loops}/{buffer_size} ({100*num_self_loops/buffer_size:.1f}%)\")\n",
    "else:\n",
    "    print(\"Replay buffer is empty.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08339ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GENERATING VISUALIZATIONS\n",
      "================================================================================\n",
      "âœ“ Saved training curves to results/run_20251021_110111/training_curves.png\n",
      "âœ“ Saved metrics plot to results/run_20251021_110111/metrics_over_time.png\n",
      "âœ“ Saved confusion matrices to results/run_20251021_110111/confusion_matrices.png\n",
      "âœ“ Saved trajectory lengths to results/run_20251021_110111/trajectory_lengths.png\n",
      "âœ“ Saved best rules to results/run_20251021_110111/best_rules.txt\n",
      "âœ“ Saved summary dashboard to results/run_20251021_110111/summary_dashboard.png\n",
      "\n",
      "âœ“ All visualizations saved to: results/run_20251021_110111\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "TRAINING COMPLETE\n",
      "================================================================================\n",
      "Results saved to: results/run_20251021_110111\n",
      "\n",
      "Generated files:\n",
      "  - training_curves.png       : Reward and loss over time\n",
      "  - metrics_over_time.png     : Precision, recall, F1-score\n",
      "  - confusion_matrices.png    : Top rules' confusion matrices\n",
      "  - trajectory_lengths.png    : Trajectory length distribution\n",
      "  - best_rules.txt            : Top 20 discovered rules\n",
      "  - summary_dashboard.png     : Comprehensive overview\n",
      "  - config.json               : Training configuration\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate all visualizations\n",
    "visualizer.finalize()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Results saved to: {visualizer.run_dir}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - training_curves.png       : Reward and loss over time\")\n",
    "print(\"  - metrics_over_time.png     : Precision, recall, F1-score\")\n",
    "print(\"  - confusion_matrices.png    : Top rules' confusion matrices\")\n",
    "print(\"  - trajectory_lengths.png    : Trajectory length distribution\")\n",
    "print(\"  - best_rules.txt            : Top 20 discovered rules\")\n",
    "print(\"  - summary_dashboard.png     : Comprehensive overview\")\n",
    "print(\"  - config.json               : Training configuration\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408957fe",
   "metadata": {},
   "source": [
    "# Embedding Analysis: Testing Semantic Equivalence Detection\n",
    "\n",
    "Now that we have a **trained** graph encoder, let's test whether it can distinguish between semantically different rules while treating semantically equivalent rules similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa663bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from src.logic_structures import Rule, Atom, Variable\n",
    "\n",
    "def create_test_rule(head_pred, head_args, body_atoms_list):\n",
    "    \"\"\"Create a rule for testing embeddings.\"\"\"\n",
    "    head_vars = [Variable(id=vid) for vid in head_args]\n",
    "    head = Atom(predicate_name=head_pred, args=tuple(head_vars))\n",
    "    \n",
    "    body_atoms = []\n",
    "    for pred_name, var_ids in body_atoms_list:\n",
    "        vars = [Variable(id=vid) for vid in var_ids]\n",
    "        body_atoms.append(Atom(predicate_name=pred_name, args=tuple(vars)))\n",
    "    \n",
    "    rule = Rule(head=head, body=tuple(body_atoms))\n",
    "    return [rule]  # Return as Theory (list of rules)\n",
    "\n",
    "def get_embedding(theory, graph_constructor, state_encoder):\n",
    "    \"\"\"Extract embedding for a theory using the trained encoder.\"\"\"\n",
    "    graph_data = graph_constructor.theory_to_graph(theory)\n",
    "    state_embedding, _ = state_encoder(graph_data)\n",
    "    return state_embedding.squeeze(0).detach().numpy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"GRAPH EMBEDDING ANALYSIS (TRAINED ENCODER)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test 1: Variable Renaming (Should be similar)\n",
    "print(\"\\nTest 1: Variable Renaming (Semantic Equivalence)\")\n",
    "print(\"-\" * 80)\n",
    "rule1 = create_test_rule('grandparent', [0, 1], [('parent', (0, 2)), ('parent', (2, 1))])\n",
    "rule2 = create_test_rule('grandparent', [10, 11], [('parent', (10, 12)), ('parent', (12, 11))])\n",
    "\n",
    "emb1 = get_embedding(rule1, graph_constructor, state_encoder)\n",
    "emb2 = get_embedding(rule2, graph_constructor, state_encoder)\n",
    "sim_rename = cosine_similarity([emb1], [emb2])[0, 0]\n",
    "\n",
    "print(f\"Rule 1: grandparent(X0, X1) :- parent(X0, X2), parent(X2, X1)\")\n",
    "print(f\"Rule 2: grandparent(X10, X11) :- parent(X10, X12), parent(X12, X11)\")\n",
    "print(f\"Cosine Similarity: {sim_rename:.6f}\")\n",
    "print(f\"Result: {'âœ“ PASS' if sim_rename > 0.95 else 'âœ— FAIL'} (Expected: >0.95)\")\n",
    "\n",
    "# Test 2: Different Semantics (Should be different)\n",
    "print(\"\\n\\nTest 2: Different Semantics (Similar Syntax)\")\n",
    "print(\"-\" * 80)\n",
    "rule3 = create_test_rule('grandparent', [0, 1], [('parent', (0, 2)), ('parent', (2, 1))])  # Correct\n",
    "rule4 = create_test_rule('grandparent', [0, 1], [('parent', (0, 2)), ('parent', (1, 2))])  # Wrong (sibling-like)\n",
    "\n",
    "emb3 = get_embedding(rule3, graph_constructor, state_encoder)\n",
    "emb4 = get_embedding(rule4, graph_constructor, state_encoder)\n",
    "sim_different = cosine_similarity([emb3], [emb4])[0, 0]\n",
    "\n",
    "print(f\"Rule 3 (correct): grandparent(X0, X1) :- parent(X0, X2), parent(X2, X1)\")\n",
    "print(f\"Rule 4 (wrong):   grandparent(X0, X1) :- parent(X0, X2), parent(X1, X2)\")\n",
    "print(f\"Cosine Similarity: {sim_different:.6f}\")\n",
    "print(f\"Result: {'âœ“ PASS' if sim_different < 0.90 else 'âœ— FAIL'} (Expected: <0.90)\")\n",
    "\n",
    "# Test 3: Predicate Order (Should be similar)\n",
    "print(\"\\n\\nTest 3: Predicate Order Swap (Semantic Equivalence)\")\n",
    "print(\"-\" * 80)\n",
    "rule5 = create_test_rule('rule', [0, 1], [('parent', (0, 2)), ('parent', (2, 1))])\n",
    "rule6 = create_test_rule('rule', [0, 1], [('parent', (2, 1)), ('parent', (0, 2))])\n",
    "\n",
    "emb5 = get_embedding(rule5, graph_constructor, state_encoder)\n",
    "emb6 = get_embedding(rule6, graph_constructor, state_encoder)\n",
    "sim_order = cosine_similarity([emb5], [emb6])[0, 0]\n",
    "\n",
    "print(f\"Rule 5: rule(X0, X1) :- parent(X0, X2), parent(X2, X1)\")\n",
    "print(f\"Rule 6: rule(X0, X1) :- parent(X2, X1), parent(X0, X2)\")\n",
    "print(f\"Cosine Similarity: {sim_order:.6f}\")\n",
    "print(f\"Result: {'âœ“ PASS' if sim_order > 0.90 else 'âœ— FAIL'} (Expected: >0.90)\")\n",
    "\n",
    "# Test 4: Different Rule Lengths\n",
    "print(\"\\n\\nTest 4: Different Rule Lengths\")\n",
    "print(\"-\" * 80)\n",
    "rule7 = create_test_rule('rule', [0, 1], [('parent', (0, 1))])  # Short\n",
    "rule8 = create_test_rule('rule', [0, 1], [('parent', (0, 2)), ('parent', (2, 3)), ('parent', (3, 1))])  # Long\n",
    "\n",
    "emb7 = get_embedding(rule7, graph_constructor, state_encoder)\n",
    "emb8 = get_embedding(rule8, graph_constructor, state_encoder)\n",
    "sim_length = cosine_similarity([emb7], [emb8])[0, 0]\n",
    "\n",
    "print(f\"Rule 7 (short): rule(X0, X1) :- parent(X0, X1)\")\n",
    "print(f\"Rule 8 (long):  rule(X0, X1) :- parent(X0, X2), parent(X2, X3), parent(X3, X1)\")\n",
    "print(f\"Cosine Similarity: {sim_length:.6f}\")\n",
    "print(f\"Result: Informational (different complexity)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "in4z4hrdb0i",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive similarity matrix visualization\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"COMPREHENSIVE SIMILARITY MATRIX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Collect all embeddings\n",
    "all_embeddings = np.array([emb1, emb2, emb3, emb4, emb5, emb6, emb7, emb8])\n",
    "similarity_matrix = cosine_similarity(all_embeddings)\n",
    "\n",
    "rule_labels = [\n",
    "    \"R1: GP(X,Y):-P(X,Z),P(Z,Y)\",\n",
    "    \"R2: GP(A,B):-P(A,C),P(C,B) [renamed]\",\n",
    "    \"R3: GP(X,Y):-P(X,Z),P(Z,Y) [correct]\",\n",
    "    \"R4: GP(X,Y):-P(X,Z),P(Y,Z) [wrong]\",\n",
    "    \"R5: R(X,Y):-P(X,Z),P(Z,Y)\",\n",
    "    \"R6: R(X,Y):-P(Z,Y),P(X,Z) [swapped]\",\n",
    "    \"R7: R(X,Y):-P(X,Y) [short]\",\n",
    "    \"R8: R(X,Y):-P(X,Z),P(Z,W),P(W,Y) [long]\"\n",
    "]\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    similarity_matrix,\n",
    "    annot=True,\n",
    "    fmt='.3f',\n",
    "    cmap='RdYlGn',\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    xticklabels=rule_labels,\n",
    "    yticklabels=rule_labels,\n",
    "    cbar_kws={'label': 'Cosine Similarity'}\n",
    ")\n",
    "plt.title('Graph Embedding Similarity Matrix (TRAINED Encoder)\\n(Green = More Similar, Red = Less Similar)', \n",
    "          fontsize=14, pad=20)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=9)\n",
    "plt.yticks(rotation=0, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{visualizer.run_dir}/embedding_similarity_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ“ Similarity matrix saved to: {visualizer.run_dir}/embedding_similarity_matrix.png\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "test_results = [\n",
    "    (\"Variable Renaming (R1 vs R2)\", sim_rename, sim_rename > 0.95, \"Should be similar\"),\n",
    "    (\"Different Semantics (R3 vs R4)\", sim_different, sim_different < 0.90, \"Should be different\"),\n",
    "    (\"Predicate Order (R5 vs R6)\", sim_order, sim_order > 0.90, \"Should be similar\"),\n",
    "]\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "for test_name, sim_value, passed, expectation in test_results:\n",
    "    status = \"âœ“ PASS\" if passed else \"âœ— FAIL\"\n",
    "    print(f\"  {status} - {test_name}: {sim_value:.4f} ({expectation})\")\n",
    "\n",
    "all_passed = all(result[2] for result in test_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "if all_passed:\n",
    "    print(\"âœ“ OVERALL: All critical tests passed!\")\n",
    "    print(\"The TRAINED encoder successfully captures semantic differences.\")\n",
    "else:\n",
    "    print(\"âœ— OVERALL: Some tests failed\")\n",
    "    print(\"The encoder may still have issues distinguishing semantic differences.\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n\\nKey Insights:\")\n",
    "print(f\"  - Same rule with renamed variables: {sim_rename:.4f} similarity\")\n",
    "print(f\"  - Different semantics (chain vs convergent): {sim_different:.4f} similarity\")\n",
    "print(f\"  - Same rule with swapped order: {sim_order:.4f} similarity\")\n",
    "print(f\"  - Short vs long rules: {sim_length:.4f} similarity\")\n",
    "print(\"\\nNote: Training the encoder through GFlowNet helps it learn to distinguish\")\n",
    "print(\"      structurally different rules based on their reward feedback.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imea7c01pcr",
   "source": "# Embedding Trajectory Visualization\n\nVisualize how embeddings evolve step-by-step during trajectory generation. This shows:\n- Whether embeddings diverge meaningfully as rules are constructed\n- Whether high-reward trajectories follow different paths than low-reward ones\n- How much each action changes the embedding representation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "h07786iv0pm",
   "source": "from visualize_embedding_trajectories import EmbeddingTrajectoryVisualizer\n\nprint(\"=\" * 80)\nprint(\"EMBEDDING TRAJECTORY VISUALIZATION\")\nprint(\"=\" * 80)\nprint(\"\\nThis visualization shows how embeddings evolve as rules are constructed.\")\nprint(\"Each trajectory is a path through embedding space.\\n\")\n\n# Create visualizer\nemb_viz = EmbeddingTrajectoryVisualizer(\n    trainer=trainer,\n    graph_constructor=graph_constructor,\n    state_encoder=state_encoder\n)\n\n# Collect trajectories\nprint(\"Sampling trajectories to visualize embedding evolution...\")\ntrajectories_data = emb_viz.collect_trajectory_embeddings(\n    initial_state=initial_state,\n    positives=positive_examples,\n    negatives=negative_examples,\n    num_trajectories=10,  # Sample 10 trajectories\n    max_steps=5          # Up to 5 steps each\n)\n\n# Generate all visualizations\nprint(\"\\nGenerating visualizations...\")\nfigs = emb_viz.visualize_all(\n    trajectories_data,\n    output_dir=visualizer.run_dir,\n    prefix='embedding_trajectory'\n)\n\n# Show first two plots\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "g620ft49zu",
   "source": "# Analyze trajectory patterns\nprint(\"\\n\" + \"=\" * 80)\nprint(\"TRAJECTORY ANALYSIS\")\nprint(\"=\" * 80)\n\n# Compute statistics\nhigh_reward_trajs = [t for t in trajectories_data if t['reward'] > 0.5]\nlow_reward_trajs = [t for t in trajectories_data if t['reward'] <= 0.5]\n\nprint(f\"\\nSampled {len(trajectories_data)} trajectories:\")\nprint(f\"  - High reward (>0.5): {len(high_reward_trajs)}\")\nprint(f\"  - Low reward (â‰¤0.5):  {len(low_reward_trajs)}\")\n\n# Average trajectory length\navg_length = np.mean([t['length'] for t in trajectories_data])\nprint(f\"\\nAverage trajectory length: {avg_length:.2f} steps\")\n\n# Compute average distance traveled in embedding space\ndistances_traveled = []\nfor traj in trajectories_data:\n    embeddings = traj['embeddings']\n    total_distance = 0.0\n    for i in range(1, len(embeddings)):\n        total_distance += np.linalg.norm(embeddings[i] - embeddings[i-1])\n    distances_traveled.append(total_distance)\n\navg_distance = np.mean(distances_traveled)\nprint(f\"Average distance traveled in embedding space: {avg_distance:.4f}\")\n\n# Compare high vs low reward trajectories\nif high_reward_trajs and low_reward_trajs:\n    high_reward_distances = []\n    low_reward_distances = []\n    \n    for traj in high_reward_trajs:\n        embeddings = traj['embeddings']\n        dist = sum(np.linalg.norm(embeddings[i] - embeddings[i-1]) \n                   for i in range(1, len(embeddings)))\n        high_reward_distances.append(dist)\n    \n    for traj in low_reward_trajs:\n        embeddings = traj['embeddings']\n        dist = sum(np.linalg.norm(embeddings[i] - embeddings[i-1]) \n                   for i in range(1, len(embeddings)))\n        low_reward_distances.append(dist)\n    \n    print(f\"\\nEmbedding space traveled:\")\n    print(f\"  - High-reward trajectories: {np.mean(high_reward_distances):.4f}\")\n    print(f\"  - Low-reward trajectories:  {np.mean(low_reward_distances):.4f}\")\n    \n    if np.mean(high_reward_distances) > np.mean(low_reward_distances):\n        print(\"\\n  â†’ High-reward trajectories explore more of the embedding space\")\n    else:\n        print(\"\\n  â†’ Low-reward trajectories explore more of the embedding space\")\n\n# Action distribution\nall_actions = []\nfor traj in trajectories_data:\n    all_actions.extend([a for a in traj['actions'] if a != 'FINAL'])\n\nfrom collections import Counter\naction_counts = Counter(all_actions)\n\nprint(f\"\\nAction distribution across all trajectories:\")\nfor action, count in action_counts.most_common():\n    pct = 100 * count / len(all_actions)\n    print(f\"  - {action}: {count} ({pct:.1f}%)\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"INTERPRETATION GUIDE\")\nprint(\"=\" * 80)\nprint(\"\\nWhat to look for in the visualizations:\")\nprint(\"\\n1. PCA/t-SNE plots:\")\nprint(\"   âœ“ GOOD: Trajectories fan out and explore different regions\")\nprint(\"   âœ— BAD:  All trajectories cluster together (embeddings too similar)\")\n\nprint(\"\\n2. Distance evolution plots:\")\nprint(\"   âœ“ GOOD: High-reward trajectories follow different paths than low-reward\")\nprint(\"   âœ— BAD:  All trajectories follow similar paths regardless of reward\")\n\nprint(\"\\n3. Similarity heatmap:\")\nprint(\"   âœ“ GOOD: Block structure visible (different trajectories are different)\")\nprint(\"   âœ— BAD:  Uniformly high similarity (all states look the same)\")\n\nprint(\"\\n4. Action-colored plot:\")\nprint(\"   âœ“ GOOD: Different action types cluster in different regions\")\nprint(\"   âœ— BAD:  All action types overlap completely\")\n\nprint(\"\\n\" + \"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "zkjc7dbqe9",
   "metadata": {},
   "source": [
    "# Policy Graph Visualization\n",
    "\n",
    "Visualize the trained GFlowNet policy as a directed graph where:\n",
    "- **Nodes** = States (rules under construction)\n",
    "- **Edges** = Actions (ADD_ATOM, UNIFY_VARIABLES, TERMINATE)\n",
    "- **Edge width** = Action probability\n",
    "- **Colors**: Blue (ADD_ATOM), Green (UNIFY_VARIABLES), Red (TERMINATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rrhbjq5fgi9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualize_gflownet_graph import GFlowNetGraphVisualizer\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"POLICY GRAPH VISUALIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create visualizer\n",
    "policy_viz = GFlowNetGraphVisualizer(\n",
    "    trainer=trainer,\n",
    "    predicate_vocab=predicate_vocab,\n",
    "    predicate_arities=predicate_arities,\n",
    "    max_body_length=config['max_body_length']\n",
    ")\n",
    "\n",
    "# Explore the policy graph starting from initial state\n",
    "print(\"\\nExploring policy graph from initial state...\")\n",
    "print(\"Parameters:\")\n",
    "print(f\"  - Max depth: 3\")\n",
    "print(f\"  - Min probability threshold: 0.05\")\n",
    "print(f\"  - Max branches per state: 3\")\n",
    "\n",
    "policy_viz.explore_from_state(\n",
    "    initial_state=initial_state,\n",
    "    max_depth=3,\n",
    "    min_prob=0.05,\n",
    "    max_branches=3\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Explored {len(policy_viz.graph.nodes)} states\")\n",
    "print(f\"âœ“ Found {len(policy_viz.graph.edges)} actions\")\n",
    "\n",
    "# Visualize the graph\n",
    "output_path = f'{visualizer.run_dir}/policy_graph.png'\n",
    "policy_viz.visualize(output_path=output_path, figsize=(20, 14))\n",
    "\n",
    "# Print top probability paths\n",
    "policy_viz.print_paths(max_paths=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7gdich29k6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze policy behavior at different states\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"POLICY BEHAVIOR ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Analyze initial state\n",
    "print(\"\\n1. Initial State Analysis\")\n",
    "print(\"-\" * 80)\n",
    "action_probs, _, _, _ = policy_viz.get_action_probabilities(initial_state)\n",
    "print(f\"Initial state: {theory_to_string(initial_state)}\")\n",
    "print(f\"\\nAction probabilities:\")\n",
    "print(f\"  - ADD_ATOM:        {action_probs[0]:.4f}\")\n",
    "print(f\"  - UNIFY_VARIABLES: {action_probs[1]:.4f}\")\n",
    "print(f\"  - TERMINATE:       {action_probs[2]:.4f}\")\n",
    "\n",
    "if action_probs[0] > 0.5:\n",
    "    print(\"\\nâœ“ Policy prefers adding atoms (exploration)\")\n",
    "    atom_probs = policy_viz.get_atom_probabilities(initial_state)\n",
    "    top_pred_idx = np.argmax(atom_probs)\n",
    "    top_pred = predicate_vocab[top_pred_idx]\n",
    "    print(f\"  Most likely predicate to add: {top_pred} (prob: {atom_probs[top_pred_idx]:.4f})\")\n",
    "\n",
    "# Sample a trajectory and analyze intermediate states\n",
    "print(\"\\n\\n2. Trajectory Analysis\")\n",
    "print(\"-\" * 80)\n",
    "print(\"Sampling a trajectory to see policy behavior...\")\n",
    "\n",
    "trajectory, reward = trainer.generate_trajectory(\n",
    "    initial_state, positive_examples, negative_examples, max_steps=5\n",
    ")\n",
    "\n",
    "print(f\"\\nTrajectory length: {len(trajectory)} steps\")\n",
    "print(f\"Final reward: {reward:.4f}\\n\")\n",
    "\n",
    "for i, step in enumerate(trajectory):\n",
    "    state_str = theory_to_string(step.state)\n",
    "    action_type = step.action_type\n",
    "    \n",
    "    print(f\"Step {i+1}:\")\n",
    "    print(f\"  State: {state_str if state_str else '[empty]'}\")\n",
    "    print(f\"  Action taken: {action_type}\")\n",
    "    print(f\"  Log probability: {step.log_pf:.4f}\")\n",
    "    \n",
    "    # Get action distribution at this state\n",
    "    action_probs, _, _, _ = policy_viz.get_action_probabilities(step.state)\n",
    "    print(f\"  Action distribution: ADD={action_probs[0]:.3f}, UNIFY={action_probs[1]:.3f}, TERM={action_probs[2]:.3f}\")\n",
    "    print()\n",
    "\n",
    "final_state_str = theory_to_string(trajectory[-1].next_state) if trajectory else \"N/A\"\n",
    "print(f\"Final state: {final_state_str}\")\n",
    "print(f\"Final reward: {reward:.4f}\")\n",
    "\n",
    "# Statistics on action preferences\n",
    "print(\"\\n\\n3. Overall Policy Statistics\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "action_types = [step.action_type for step in trajectory]\n",
    "add_count = action_types.count('ADD_ATOM')\n",
    "unify_count = action_types.count('UNIFY_VARIABLES')\n",
    "term_count = action_types.count('TERMINATE')\n",
    "\n",
    "print(f\"Action distribution in sampled trajectory:\")\n",
    "print(f\"  - ADD_ATOM:        {add_count}/{len(trajectory)} ({100*add_count/len(trajectory):.1f}%)\")\n",
    "print(f\"  - UNIFY_VARIABLES: {unify_count}/{len(trajectory)} ({100*unify_count/len(trajectory):.1f}%)\")\n",
    "print(f\"  - TERMINATE:       {term_count}/{len(trajectory)} ({100*term_count/len(trajectory):.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9knp9jzfcu",
   "metadata": {},
   "source": [
    "# Loss vs Reward Mismatch Analysis\n",
    "\n",
    "Diagnose the \"zero flow problem\" where the loss function is minimized but the policy doesn't find good rules. This happens when the model learns to assign uniformly low probabilities everywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zf3hb67x188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze_loss_reward_mismatch import LossRewardAnalyzer\n",
    "\n",
    "# Create analyzer\n",
    "analyzer = LossRewardAnalyzer(trainer)\n",
    "\n",
    "# Prepare states for analysis\n",
    "analysis_states = {\n",
    "    'initial': initial_state,\n",
    "    'positives': positive_examples,\n",
    "    'negatives': negative_examples\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPREHENSIVE LOSS/REWARD DIAGNOSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nThis analysis checks for common GFlowNet training problems:\")\n",
    "print(\"  1. Zero Flow Problem - Model assigns low probabilities everywhere\")\n",
    "print(\"  2. Low Reward Problem - Policy doesn't find good rules\")\n",
    "print(\"  3. Vanishing Gradients - Learning has stalled\")\n",
    "print(\"\\nRunning diagnosis...\")\n",
    "\n",
    "# Run comprehensive diagnosis\n",
    "diagnosis = analyzer.diagnose_zero_flow_problem(\n",
    "    states=analysis_states,\n",
    "    num_samples=50\n",
    ")\n",
    "\n",
    "# Save figures\n",
    "flow_fig = diagnosis['flow_fig']\n",
    "reward_fig = diagnosis['reward_fig']\n",
    "\n",
    "flow_fig.savefig(f'{visualizer.run_dir}/flow_analysis.png', dpi=300, bbox_inches='tight')\n",
    "reward_fig.savefig(f'{visualizer.run_dir}/reward_analysis.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(f\"\\nâœ“ Flow analysis saved to: {visualizer.run_dir}/flow_analysis.png\")\n",
    "print(f\"âœ“ Reward analysis saved to: {visualizer.run_dir}/reward_analysis.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4mqzp66kfg8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed interpretation of results\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED INTERPRETATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Check diagnosis results\n",
    "has_zero_flow = diagnosis['zero_flow_problem']\n",
    "has_low_reward = diagnosis['low_reward_problem']\n",
    "\n",
    "flow_stats = diagnosis['flow_stats']\n",
    "reward_stats = diagnosis['reward_stats']\n",
    "\n",
    "print(\"\\n1. Flow Analysis Results:\")\n",
    "print(f\"   - Learned log Z: {flow_stats['log_Z']:.4f}\")\n",
    "print(f\"   - Mean log P_F: {flow_stats['mean_log_pf']:.4f}\")\n",
    "print(f\"   - Std log P_F:  {flow_stats['std_log_pf']:.4f}\")\n",
    "\n",
    "if has_zero_flow:\n",
    "    print(\"   âš ï¸  Zero flow problem detected!\")\n",
    "    print(\"      The model is assigning very low probabilities to all actions.\")\n",
    "else:\n",
    "    print(\"   âœ“ Flow values look reasonable\")\n",
    "\n",
    "print(\"\\n2. Reward Analysis Results:\")\n",
    "print(f\"   - Mean reward: {np.mean(reward_stats['rewards']):.4f}\")\n",
    "print(f\"   - Max reward:  {np.max(reward_stats['rewards']):.4f}\")\n",
    "print(f\"   - % Zero rewards: {100 * np.sum(reward_stats['rewards'] < 1e-6) / len(reward_stats['rewards']):.1f}%\")\n",
    "print(f\"   - % High rewards (>0.8): {100 * np.sum(reward_stats['rewards'] > 0.8) / len(reward_stats['rewards']):.1f}%\")\n",
    "\n",
    "if has_low_reward:\n",
    "    print(\"   âš ï¸  Low reward problem detected!\")\n",
    "    print(\"      The policy is not finding good rules.\")\n",
    "else:\n",
    "    print(\"   âœ“ Policy is finding decent rules\")\n",
    "\n",
    "print(\"\\n3. Connection to Training Results:\")\n",
    "print(f\"   - Final average reward (from training): {final_avg_reward:.4f}\")\n",
    "print(f\"   - Max reward achieved: {max_reward:.4f}\")\n",
    "print(f\"   - High-reward episodes (>0.8): {high_reward_count}/{num_episodes}\")\n",
    "\n",
    "# Determine root cause\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ROOT CAUSE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if has_zero_flow and has_low_reward:\n",
    "    print(\"\\nðŸ”´ CRITICAL: Both zero flow AND low reward problems detected\")\n",
    "    print(\"\\nLikely causes:\")\n",
    "    print(\"  1. Encoder produces similar embeddings for all states (see embedding analysis)\")\n",
    "    print(\"  2. Reward signal is too sparse or weak\")\n",
    "    print(\"  3. Learning rate may be too high, causing instability\")\n",
    "    print(\"  4. Model has converged to a local minimum (uniform low probabilities)\")\n",
    "    \n",
    "elif has_low_reward and not has_zero_flow:\n",
    "    print(\"\\nðŸŸ¡ Low rewards but flow values are reasonable\")\n",
    "    print(\"\\nLikely causes:\")\n",
    "    print(\"  1. Policy needs more exploration\")\n",
    "    print(\"  2. Encoder cannot distinguish good from bad partial rules\")\n",
    "    print(\"  3. Max body length may be too restrictive\")\n",
    "    \n",
    "elif has_zero_flow and not has_low_reward:\n",
    "    print(\"\\nðŸŸ¡ Zero flow detected but rewards are okay\")\n",
    "    print(\"\\nLikely causes:\")\n",
    "    print(\"  1. Model is under-confident (could benefit from temperature tuning)\")\n",
    "    print(\"  2. Log probabilities are scaled differently than expected\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nðŸŸ¢ Training appears healthy!\")\n",
    "    print(\"\\nThe model shows:\")\n",
    "    print(\"  âœ“ Reasonable flow values\")\n",
    "    print(\"  âœ“ Good reward distribution\")\n",
    "    print(\"  Continue training or experiment with harder problems.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sbiwbntvfsi",
   "metadata": {},
   "source": "# Final Summary: Complete Pipeline with Advanced Diagnostics\n\nThis notebook demonstrates a complete GFlowNet-ILP pipeline with state-of-the-art diagnostics:\n\n## Pipeline Stages:\n1. **âœ“ Contrastive Pre-Training** - Teaches encoder to distinguish semantic differences\n2. **âœ“ GFlowNet Training** - Learns to generate high-quality logic rules\n3. **âœ“ Embedding Analysis** - Verifies encoder can distinguish semantics (post-training)\n4. **âœ“ Embedding Trajectory Visualization** â† NEW! - Shows how embeddings evolve step-by-step\n5. **âœ“ Policy Visualization** - Shows what the GFlowNet has learned\n6. **âœ“ Loss/Reward Diagnosis** - Identifies any training problems\n\n## Key Innovations:\n\n### 1. Contrastive Pre-Training\nSolves the critical problem where untrained encoders produce nearly identical embeddings for all rules, making GFlowNet learning impossible.\n\n### 2. Embedding Trajectory Visualization\n**NEW!** Shows how embeddings evolve as rules are constructed:\n- **6 different visualizations** (PCA 2D/3D, t-SNE, similarity heatmap, distance evolution, action clustering)\n- Reveals whether high-reward and low-reward trajectories take different paths through embedding space\n- Diagnoses whether the encoder is learning meaningful representations during construction\n\n## Generated Visualizations:\nThe notebook produces **18 visualization files** organized into 4 categories:\n- Pre-training (1 file)\n- Training (7 files)\n- Embedding Trajectories (6 files) â† NEW!\n- Diagnostics (4 files)\n\nCheck the results directory for all generated visualizations!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bq8ka6pkbep",
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# List all generated files\nprint(\"=\" * 80)\nprint(\"GENERATED FILES SUMMARY\")\nprint(\"=\" * 80)\nprint(f\"\\nAll results saved to: {visualizer.run_dir}\\n\")\n\nprint(\"Pre-training Visualizations:\")\nprint(\"  âœ“ contrastive_pretraining_results.png - Before/after pre-training comparison\")\n\nprint(\"\\nTraining Visualizations:\")\nprint(\"  âœ“ training_curves.png       - Reward and loss over time\")\nprint(\"  âœ“ metrics_over_time.png     - Precision, recall, F1-score\")\nprint(\"  âœ“ confusion_matrices.png    - Top rules' confusion matrices\")\nprint(\"  âœ“ trajectory_lengths.png    - Trajectory length distribution\")\nprint(\"  âœ“ summary_dashboard.png     - Comprehensive overview\")\nprint(\"  âœ“ best_rules.txt            - Top 20 discovered rules\")\nprint(\"  âœ“ config.json               - Training configuration\")\n\nprint(\"\\nEmbedding Trajectory Visualizations:\")\nprint(\"  âœ“ embedding_trajectory_pca_2d.png       - 2D PCA trajectory paths\")\nprint(\"  âœ“ embedding_trajectory_pca_3d.png       - 3D PCA trajectory paths\")\nprint(\"  âœ“ embedding_trajectory_tsne.png         - t-SNE trajectory paths\")\nprint(\"  âœ“ embedding_trajectory_similarity.png   - Step-by-step similarity heatmap\")\nprint(\"  âœ“ embedding_trajectory_distance_evolution.png - Distance evolution plots\")\nprint(\"  âœ“ embedding_trajectory_by_action.png    - Embeddings colored by action type\")\n\nprint(\"\\nDiagnostic Visualizations:\")\nprint(\"  âœ“ embedding_similarity_matrix.png - Encoder semantic equivalence test\")\nprint(\"  âœ“ policy_graph.png                - GFlowNet policy as state-action graph\")\nprint(\"  âœ“ flow_analysis.png               - Flow value distribution\")\nprint(\"  âœ“ reward_analysis.png             - Reward distribution analysis\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"ANALYSIS COMPLETE!\")\nprint(\"=\" * 80)\n\n# Count files\nif os.path.exists(visualizer.run_dir):\n    files = [f for f in os.listdir(visualizer.run_dir) if not f.startswith('.')]\n    print(f\"\\nTotal files generated: {len(files)}\")\n    print(f\"Results directory: {visualizer.run_dir}\")\nelse:\n    print(\"\\nResults directory not found!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MarinaWeb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}